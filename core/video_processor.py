import time
import requests
import requests.adapters
from PyQt6.QtCore import QRunnable
import os
import subprocess
import sys
from datetime import datetime
from deep_translator import GoogleTranslator
from core.worker_signals import WorkerSignals
from core.speech_recognizer import SpeechRecognizer, SubtitleFormatter
from utils.logger import VideoLogger
import threading
import json
import platform
import multiprocessing as mp
import queue
from typing import Dict, Any, Optional, List
from config import OPENAI_MODEL, OPENAI_CUSTOM_PROMPT, OPENAI_MAX_CHARS_PER_BATCH, OPENAI_MAX_ENTRIES_PER_BATCH, MAX_PROCESSES


class ContentFilteredException(Exception):
    """Exception raised when content is filtered by OpenAI safety system"""
    pass


class VideoProcessor(QRunnable):
    def __init__(self, video_path, engine, api_settings, cache_dir,
                 progress_callback=None, status_callback=None):
        super().__init__()
        self.video_path = video_path
        self.engine = engine
        self.api_settings = api_settings
        self.cache_dir = cache_dir
        self.progress_callback = progress_callback
        self.status_callback = status_callback
        self.base_name = os.path.basename(video_path)
        self.logger = VideoLogger(cache_dir)
        self.signals = WorkerSignals()
        
        # åˆ›å»ºå¤ç”¨çš„requestsä¼šè¯ä»¥æé«˜æ€§èƒ½
        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {self.api_settings.get('api_key', '')}",
            "Content-Type": "application/json"
        })
        
        # é…ç½®è¿æ¥æ± ä»¥æé«˜æ€§èƒ½
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,
            pool_maxsize=20,
            max_retries=3,
            pool_block=False
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
        
        # è¯­éŸ³è¯†åˆ«å™¨ - ä½¿ç”¨å•ä¾‹æ¨¡å¼çš„ Parakeet MLX
        # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œåˆå§‹åŒ–ï¼Œè€Œæ˜¯åœ¨éœ€è¦æ—¶è·å–å•ä¾‹å®ä¾‹
    
        # è·Ÿè¸ªå¤„ç†çŠ¶æ€ä»¥ç¡®ä¿æ­£ç¡®æ¸…ç†
        self._processing_complete = False
        
        # è®¡æ—¶å™¨ç›¸å…³å˜é‡
        self._start_time = None
        self._timer_thread = None
        self._timer_stop_event = threading.Event()
        
        # ç®€åŒ–çš„ç³»ç»Ÿæ£€æµ‹
        self.use_hardware_accel = self._check_hardware_acceleration()
        self.is_apple_silicon = self._is_apple_silicon()
        
        # è®°å½•ç³»ç»Ÿä¿¡æ¯
        self.logger.info(f"Video processor - Platform: {platform.system()}")
        if self.is_apple_silicon:
            self.logger.info("Apple Silicon detected - using optimized video processing")
        
        if self.use_hardware_accel:
            self.logger.info("Hardware acceleration available for video processing")
    
    def _start_timer(self):
        """å¯åŠ¨è®¡æ—¶å™¨çº¿ç¨‹"""
        self._start_time = time.time()
        self._timer_stop_event.clear()
        self._timer_thread = threading.Thread(target=self._timer_worker, daemon=True)
        self._timer_thread.start()
        
    def _stop_timer(self):
        """åœæ­¢è®¡æ—¶å™¨çº¿ç¨‹"""
        if self._timer_thread and self._timer_thread.is_alive():
            self._timer_stop_event.set()
            self._timer_thread.join(timeout=1.0)
    
    def _timer_worker(self):
        """è®¡æ—¶å™¨å·¥ä½œçº¿ç¨‹"""
        while not self._timer_stop_event.is_set():
            if self._start_time:
                elapsed = time.time() - self._start_time
                elapsed_str = self._format_elapsed_time(elapsed)
                self.signals.timer_update.emit(self.base_name, elapsed_str)
            time.sleep(1)  # æ¯ç§’æ›´æ–°ä¸€æ¬¡
    
    def _format_elapsed_time(self, elapsed_seconds):
        """æ ¼å¼åŒ–ç»è¿‡çš„æ—¶é—´ä¸º MM:SS æ ¼å¼"""
        minutes = int(elapsed_seconds // 60)
        seconds = int(elapsed_seconds % 60)
        return f"{minutes:02d}:{seconds:02d}"

    def _is_apple_silicon(self) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯Apple Silicon"""
        if platform.system() != 'Darwin':
            return False
        try:
            result = subprocess.run(['sysctl', '-n', 'hw.optional.arm64'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0 and result.stdout.strip() == '1'
        except Exception:
            return False

    def _check_hardware_acceleration(self) -> bool:
        """æ£€æŸ¥VideoToolboxç¡¬ä»¶åŠ é€Ÿæ”¯æŒ"""
        if platform.system() != 'Darwin':
            return False
        try:
            ffmpeg_path = self.get_ffmpeg_path()
            if not ffmpeg_path:
                return False
            result = subprocess.run([ffmpeg_path, '-version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0 and 'videotoolbox' in result.stdout.lower()
        except Exception:
            return False

    def report_progress(self, progress):
        self.signals.file_progress.emit(self.base_name, progress)
        if self.progress_callback:
            self.progress_callback(self.base_name, progress)

    def report_status(self, status):
        self.signals.status.emit(self.base_name, status)
        if self.status_callback:
            self.status_callback(self.base_name, status)

    def run(self):
        try:
            # å¯åŠ¨è®¡æ—¶å™¨
            self._start_timer()
            
            self.logger.info(f"Starting to process video: {self.base_name}")
            cache_paths = self.get_cache_paths()

            # Produce Audio (0-10%)
            self.report_status("Extracting audio...")
            self.report_progress(0)
            self.extract_audio(cache_paths['audio'])
            self.logger.info("Audio extraction completed")
            self.report_progress(10)

            # Generate Subtitle (10-70%)
            self.report_status("Recognizing speech...")
            self.generate_subtitles(cache_paths['audio'], cache_paths['srt'])
            self.logger.info("Subtitle generation complete")
            self.report_progress(70)

            # Translate Subtitle (70-80%)
            self.report_status("Translating subtitles...")
            with open(cache_paths['srt'], "r", encoding="utf-8") as f:
                lines = f.readlines()
            translated_content = self.translate_subtitles(lines)
            
            # Check if bilingual subtitles are empty before proceeding
            if not translated_content or translated_content.strip() == "":
                error_msg = "åŒè¯­å­—å¹•ä¸ºç©ºï¼Œè·³è¿‡è§†é¢‘åˆæˆä»»åŠ¡"
                self.logger.warning(error_msg)
                self.report_status(error_msg)
                self.report_progress(100)
                self.signals.finished.emit()
                return
            
            with open(cache_paths['bilingual_srt'], "w", encoding="utf-8") as f:
                f.write(translated_content)
            self.logger.info("Subtitle translation completed")
            self.report_progress(80)

            # Composite Video (80-100%)
            self.report_status("Synthesizing video...")
            self.burn_subtitles(cache_paths['bilingual_srt'], cache_paths['output_video'])
            self.logger.info("Video synthesis completed")
            self.report_progress(100)
            self.report_status("Processing completed!")

            # Send Completion Signal
            self.signals.finished.emit()

        except Exception as e:
            error_msg = f"Processing failed: {str(e)}"
            self.logger.error(error_msg)
            self.signals.error.emit(f"Failed to process video {self.base_name} : {str(e)}")
            self.signals.status.emit(self.base_name, error_msg)
            # Send Completion Signal even if it's failed
            self.signals.finished.emit()
        finally:
            # åœæ­¢è®¡æ—¶å™¨
            self._stop_timer()
            
            # ç¡®ä¿èµ„æºè¢«æ­£ç¡®å…³é—­
            try:
                if hasattr(self, 'session'):
                    self.session.close()
                    
                # æ³¨æ„ï¼šä¸å†éœ€è¦é‡Šæ”¾è¯­éŸ³è¯†åˆ«å™¨å†…å­˜ï¼Œå› ä¸ºä½¿ç”¨å•ä¾‹æ¨¡å¼
                # MLX æ¨¡å‹ä¼šåœ¨åº”ç”¨ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨æ¸…ç†
                    
                # æ¸…ç†æ—¥å¿—å¤„ç†å™¨
                if hasattr(self, 'logger'):
                    self.logger.cleanup()
            except Exception as cleanup_error:
                print(f"Error during cleanup: {cleanup_error}")  # ä½¿ç”¨printé¿å…å¾ªç¯ä¾èµ–

    def get_cache_paths(self):
        base_name = os.path.splitext(self.base_name)[0]
        return {
            'audio': os.path.join(self.cache_dir, f"{base_name}_audio.wav"),
            'srt': os.path.join(self.cache_dir, f"{base_name}_output.srt"),
            'bilingual_srt': os.path.join(self.cache_dir, f"{base_name}_bilingual.srt"),
            'output_video': os.path.join(
                os.path.dirname(self.video_path),
                f"{base_name}_subtitled_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                f"{os.path.splitext(self.video_path)[1]}"
            )
        }

    @staticmethod
    def get_ffmpeg_path():
        """
        è·å– ffmpeg è·¯å¾„
        - æ‰“åŒ…ç¯å¢ƒï¼šä½¿ç”¨å†…ç½®çš„ ffmpeg
        - å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ ffmpeg
        """
        # æ£€æµ‹æ˜¯å¦åœ¨ PyInstaller æ‰“åŒ…ç¯å¢ƒä¸­
        if getattr(sys, 'frozen', False):
            if platform.system() == 'Darwin':  # macOS
                # åœ¨ macOS .app åŒ…ä¸­ï¼Œæ£€æŸ¥ Contents/Frameworks ç›®å½•
                if '.app/Contents/MacOS' in sys.executable:
                    app_frameworks = os.path.join(os.path.dirname(sys.executable), '..', 'Frameworks')
                    ffmpeg_path = os.path.join(os.path.abspath(app_frameworks), 'ffmpeg')
                    if os.path.exists(ffmpeg_path):
                        return ffmpeg_path
                
                # ä¹Ÿæ£€æŸ¥å¯æ‰§è¡Œæ–‡ä»¶åŒç›®å½•
                bundle_dir = os.path.dirname(sys.executable)
                ffmpeg_path = os.path.join(bundle_dir, 'ffmpeg')
                if os.path.exists(ffmpeg_path):
                    return ffmpeg_path
            else:
                # å…¶ä»–å¹³å°çš„ PyInstaller ç¯å¢ƒ
                bundle_dir = os.path.dirname(sys.executable)
                ffmpeg_path = os.path.join(bundle_dir, 'ffmpeg')
                if os.path.exists(ffmpeg_path):
                    return ffmpeg_path
        
        # å¼€å‘ç¯å¢ƒ - ä½¿ç”¨ç³»ç»Ÿå®‰è£…çš„ ffmpeg
        possible_paths = [
            '/opt/homebrew/bin/ffmpeg',  # MacOS Homebrew
            '/usr/local/bin/ffmpeg',     # Linux/MacOS Path
            '/usr/bin/ffmpeg',           # Others
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
                
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å› None
        return None

    def check_has_audio(self):
        """æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦åŒ…å«éŸ³é¢‘æµ"""
        ffmpeg_path = self.get_ffmpeg_path()
        if not ffmpeg_path:
            return False
            
        try:
            cmd = [ffmpeg_path, "-i", self.video_path, "-hide_banner", "-f", "null", "-"]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            # æ£€æŸ¥stderrè¾“å‡ºä¸­æ˜¯å¦æœ‰éŸ³é¢‘æµä¿¡æ¯
            stderr_output = result.stderr.lower()
            return "audio:" in stderr_output or "stream #" in stderr_output and ("audio" in stderr_output or "mp3" in stderr_output or "aac" in stderr_output or "wav" in stderr_output)
        except Exception as e:
            self.logger.warning(f"Could not check audio streams: {e}")
            return True  # é»˜è®¤å‡è®¾æœ‰éŸ³é¢‘ï¼Œè®©extract_audioå¤„ç†

    def extract_audio(self, audio_path):
        ffmpeg_path = self.get_ffmpeg_path()
        if not ffmpeg_path:
            error_msg = "Could not find ffmpeg."
            if getattr(sys, 'frozen', False):
                error_msg += " Application may not be properly installed or ffmpeg not bundled correctly."
                error_msg += f" Searched in: {sys.executable} directory"
            else:
                error_msg += " Please install it first (e.g., brew install ffmpeg)."
            self.logger.error(error_msg)
            raise FileNotFoundError(error_msg)
            
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(self.video_path):
            raise FileNotFoundError(f"Video file not found: {self.video_path}")
        
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦æœ‰éŸ³é¢‘æµ
        if not self.check_has_audio():
            self.logger.warning("Video file has no audio streams, creating empty audio file")
            # åˆ›å»ºä¸€ä¸ªçŸ­æš‚çš„é™éŸ³éŸ³é¢‘æ–‡ä»¶
            try:
                cmd = [ffmpeg_path, "-f", "lavfi", "-i", "anullsrc=r=16000:cl=mono", "-t", "0.1", "-q:a", "0", audio_path, "-y"]
                subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
                return True
            except Exception as e:
                self.logger.error(f"Failed to create silent audio file: {e}")
                raise RuntimeError("Video has no audio and failed to create silent audio file")
            
        try:
            # ä½¿ç”¨ç³»ç»Ÿä¼˜åŒ–çš„ç¡¬ä»¶åŠ é€Ÿå‚æ•°
            cmd = [ffmpeg_path]
            
            # æ·»åŠ ç¡¬ä»¶åŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.use_hardware_accel:
                cmd.extend(["-hwaccel", "videotoolbox"])
                self.logger.info("Using VideoToolbox hardware acceleration for audio extraction")
            
            cmd.extend([
                "-i", self.video_path,
                "-q:a", "0",
                "-map", "a",
                "-ac", "1",  # è½¬æ¢ä¸ºå•å£°é“ä»¥å‡å°‘æ–‡ä»¶å¤§å°
                "-ar", "16000",  # é™ä½é‡‡æ ·ç‡ï¼Œå¯¹è¯­éŸ³è¯†åˆ«è¶³å¤Ÿ
                audio_path,
                "-y"
            ])
            
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=300)
            
            self.logger.info("Audio extraction completed successfully")
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if not os.path.exists(audio_path) or os.path.getsize(audio_path) == 0:
                raise RuntimeError("Audio extraction failed: output file is empty or missing")
                
            return True
        except subprocess.TimeoutExpired:
            raise RuntimeError("Audio extraction timeout: process took too long")
        except subprocess.CalledProcessError as e:
            # å¦‚æœéŸ³é¢‘æå–å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ²¡æœ‰éŸ³é¢‘æµï¼Œå°è¯•åˆ›å»ºé™éŸ³æ–‡ä»¶
            if "no such file or directory" not in str(e.stderr).lower():
                try:
                    self.logger.warning("Audio extraction failed, attempting to create silent audio file")
                    cmd = [ffmpeg_path, "-f", "lavfi", "-i", "anullsrc=r=16000:cl=mono", "-t", "0.1", "-q:a", "0", audio_path, "-y"]
                    subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
                    return True
                except Exception:
                    pass
            
            error_msg = f"Error during audio extraction: {e.stderr}"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)

    def generate_subtitles(self, audio_path, srt_path):
        """ä½¿ç”¨ Parakeet MLX ç”Ÿæˆå­—å¹• - ä½¿ç”¨å•ä¾‹æ¨¡å¼"""
        # è·å–å•ä¾‹è¯­éŸ³è¯†åˆ«å™¨
        try:
            self.logger.info("Getting Parakeet MLX speech recognizer instance...")
            self.report_progress(12)  # 10% + 2% for initialization
            
            # è·å–å•ä¾‹å®ä¾‹ï¼Œåªæœ‰ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶ä¼šè§¦å‘ä¸‹è½½å›è°ƒ
            speech_recognizer = SpeechRecognizer(
                model_name="mlx-community/parakeet-tdt-0.6b-v2",
                fp32=False,  # ä½¿ç”¨ bfloat16 ç²¾åº¦ä»¥èŠ‚çœå†…å­˜
                local_attention=True,  # ä½¿ç”¨å±€éƒ¨æ³¨æ„åŠ›å‡å°‘å†…å­˜ä½¿ç”¨
                local_attention_context_size=256,
                logger=self.logger,
                download_callback=lambda model_name: self.signals.download_started.emit(model_name),
                progress_callback=lambda percentage, downloaded_mb, total_mb, speed_mbps: (
                    self.signals.download_progress.emit(percentage, downloaded_mb, total_mb, speed_mbps),
                    self.signals.download_completed.emit() if percentage == 100 else None
                )[0],  # åªè¿”å›ç¬¬ä¸€ä¸ªç»“æœ
                status_callback=lambda message: self.signals.download_status.emit(message)
            )
            self.logger.info("Parakeet MLX model instance obtained successfully")
            
        except Exception as e:
            self.logger.error(f"Failed to get Parakeet MLX model instance: {str(e)}")
            self.signals.download_error.emit(f"Failed to get Parakeet MLX model instance: {str(e)}")
            raise RuntimeError(f"Failed to get Parakeet MLX model instance: {str(e)}")
        
        self.report_progress(20)  # æ¨¡å‹å®ä¾‹è·å–å®Œæˆï¼Œå ç”¨10%->20%çš„è¿›åº¦
        
        # ä½¿ç”¨ Parakeet MLX è¿›è¡Œè½¬å½•
        try:
            self.logger.info(f"Starting transcription of: {audio_path}")
            
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°ï¼Œå¦‚æœå¤ªå°ï¼ˆå¦‚é™éŸ³æ–‡ä»¶ï¼‰ï¼Œç›´æ¥åˆ›å»ºç©ºå­—å¹•
            if os.path.getsize(audio_path) < 1000:  # å°äº1KBï¼Œå¯èƒ½æ˜¯é™éŸ³æ–‡ä»¶
                self.logger.info("Audio file is very small, likely silent - creating empty subtitle file")
                with open(srt_path, "w", encoding="utf-8") as f:
                    f.write("")  # åˆ›å»ºç©ºå­—å¹•æ–‡ä»¶
                return
            
            # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•° - è¯­éŸ³è¯†åˆ«å ç”¨20%-70%çš„è¿›åº¦ç©ºé—´ï¼ˆ50%çš„è¿›åº¦ç©ºé—´ï¼‰
            def progress_callback(current_chunk, total_chunks):
                if total_chunks > 0:
                    # è¯­éŸ³è¯†åˆ«è¿›åº¦ï¼š20% + (current_chunk/total_chunks) * 50%
                    recognition_progress = (current_chunk / total_chunks) * 50
                    progress = 20 + recognition_progress
                    self.report_progress(min(70, int(progress)))
            
            # è¿›è¡Œè½¬å½• - ç°åœ¨æ˜¯çº¿ç¨‹å®‰å…¨çš„
            result = speech_recognizer.transcribe(
                audio_path,
                chunk_duration=120.0,  # 2åˆ†é’Ÿåˆ†å—
                overlap_duration=15.0,  # 15ç§’é‡å 
                progress_callback=progress_callback
            )
            
            self.report_progress(70)  # è½¬å½•å®Œæˆï¼Œç¡®ä¿è¾¾åˆ°70%
            
            # ä½¿ç”¨å­—å¹•æ ¼å¼åŒ–å™¨ç”Ÿæˆ SRT æ ¼å¼
            srt_content = SubtitleFormatter.to_srt(result, highlight_words=False)
            
            # å†™å…¥ SRT æ–‡ä»¶
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(srt_content)
                
            # ç»Ÿè®¡ç”Ÿæˆçš„å­—å¹•æ®µæ•°
            segment_count = len(result.sentences)
            self.logger.info(f"Transcription completed, generated {segment_count} segments")
            
        except Exception as e:
            self.logger.error(f"Transcription failed: {str(e)}")
            raise RuntimeError(f"Transcription failed: {str(e)}")

    def translate_subtitles(self, lines):
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå­—å¹•æ–‡ä»¶
            if not lines or all(not line.strip() for line in lines):
                self.logger.info("Empty subtitle file detected, skipping translation")
                return ""
            
            entries = []
            current_id = None
            current_timestamp = ""
            current_text = []
            parsing_state = "id"  # å¯èƒ½çš„çŠ¶æ€: id, timestamp, text

            for line in lines:
                line = line.strip()
                if not line:  # ç©ºè¡Œè¡¨ç¤ºä¸€ä¸ªå­—å¹•æ¡ç›®ç»“æŸ
                    if current_id is not None and current_timestamp and current_text:
                        entries.append({
                            'id': current_id,
                            'timestamp': current_timestamp,
                            'text': '\n'.join(current_text)
                        })
                    # é‡ç½®çŠ¶æ€ä¸ºè§£ææ–°æ¡ç›®çš„ID
                    current_id = None
                    current_timestamp = ""
                    current_text = []
                    parsing_state = "id"
                    continue
                
                if parsing_state == "id" and line.isdigit():
                    current_id = int(line)
                    parsing_state = "timestamp"
                elif parsing_state == "timestamp" and '-->' in line:
                    current_timestamp = line
                    parsing_state = "text"
                elif parsing_state == "text":
                    current_text.append(line)

            # å¤„ç†æ–‡ä»¶æœ«å°¾å¯èƒ½å­˜åœ¨çš„æœ€åä¸€ä¸ªæ¡ç›®
            if current_id is not None and current_timestamp and current_text:
                entries.append({
                    'id': current_id,
                    'timestamp': current_timestamp,
                    'text': '\n'.join(current_text)
                })

            total_entries = len(entries)
            if total_entries == 0:
                self.logger.warning("No valid subtitle entries found to translate")
                return ""
                
            self.logger.info(f"Starting batch translation of {total_entries} subtitle entries")
            
            # æ‰¹é‡ç¿»è¯‘æ‰€æœ‰å­—å¹• (70% -> 80%)
            self.report_progress(72)
            translated_entries = self._batch_translate_all(entries)
            self.report_progress(80)

            # Sort by ID to Ensure Correct Subtitle Ordering
            translated_entries.sort(key=lambda x: x['id'])

            # Construct Final Subtitle Content
            translated_content = ""
            for entry in translated_entries:
                translated_content += f"{entry['id']}\n{entry['timestamp']}\n{entry['text']}\n\n"

            return translated_content

        except Exception as e:
            self.signals.error.emit(f"Translation Process Failed: {str(e)}")
            raise

    def _batch_translate_all(self, entries):
        """æ‰¹é‡ç¿»è¯‘æ‰€æœ‰å­—å¹•æ¡ç›®"""
        if self.engine == "OpenAI Translate":
            return self._batch_translate_with_openai(entries)
        else:  # Google Translation
            return self._batch_translate_with_google(entries)
    
    """
    å¤–éƒ¨è°ƒç”¨
    â†“
    _batch_translate_with_openai (è°ƒåº¦å™¨)
    â†“
    â”œâ”€ å†…å®¹å°‘ â†’ _translate_openai_batch (å•æ¬¡å¤„ç†)
    â””â”€ å†…å®¹å¤š â†’ _translate_openai_multiple_batches (åˆ†æ‰¹ç®¡ç†)
                    â†“
                    å¾ªç¯è°ƒç”¨ â†’ _translate_openai_batch (å…·ä½“æ‰§è¡Œ)
    """

    def _batch_translate_with_openai(self, entries):
        """ä½¿ç”¨OpenAI APIæ‰¹é‡ç¿»è¯‘æ‰€æœ‰å­—å¹• - ä½¿ç”¨æ®µè½åˆ†éš”ç¬¦æ–¹æ¡ˆ"""
        try:
            # ä»é…ç½®æ–‡ä»¶è·å–æ‰¹å¤„ç†å‚æ•°
            max_chars_per_batch = self.api_settings.get("max_chars_per_batch", OPENAI_MAX_CHARS_PER_BATCH)
            max_entries_per_batch = self.api_settings.get("max_entries_per_batch", OPENAI_MAX_ENTRIES_PER_BATCH)
            
            total_chars = sum(len(entry['text']) for entry in entries)
            
            if total_chars <= max_chars_per_batch and len(entries) <= max_entries_per_batch:
                # å†…å®¹è¾ƒå°‘ï¼Œä½¿ç”¨å•ä¸€æ‰¹é‡è¯·æ±‚
                self.logger.info(f"Content size {total_chars} chars, {len(entries)} entries - using single batch request")
                return self._translate_openai_batch(entries)
            else:
                # å†…å®¹è¿‡å¤šï¼Œéœ€è¦åˆ†æ‰¹å¤„ç†
                self.logger.info(f"Content size {total_chars} chars, {len(entries)} entries - using multiple batch processing")
                return self._translate_openai_multiple_batches(entries, max_chars_per_batch, max_entries_per_batch)
                
        except Exception as e:
            self.logger.error(f"OpenAI batch translation failed: {str(e)}")
            raise
    
    def _translate_openai_batch(self, entries):
        """OpenAIå•æ‰¹æ¬¡ç¿»è¯‘ - ä½¿ç”¨æ®µè½åˆ†éš”ç¬¦æ–¹æ¡ˆ"""
        # æ„å»ºç¿»è¯‘æ–‡æœ¬ - ä½¿ç”¨ %% åˆ†éš”ç¬¦
        if len(entries) == 1:
            # å•æ®µè½ï¼Œç›´æ¥ç¿»è¯‘
            text_to_translate = entries[0]['text']
        else:
            # å¤šæ®µè½ï¼Œä½¿ç”¨ %% åˆ†éš”
            texts = [entry['text'] for entry in entries]
            text_to_translate = '\n%%\n'.join(texts)
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è‡ªå®šä¹‰prompt
        system_prompt = OPENAI_CUSTOM_PROMPT

        user_prompt = f"Translate to Chinese (output translation only):\n\n{text_to_translate}"
        
        data = {
            "model": self.api_settings.get("model", OPENAI_MODEL),
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0,
            "max_tokens": 8000  # é€‚ä¸­çš„tokené™åˆ¶
        }

        response = self.session.post(
            f"{self.api_settings['base_url']}/v1/chat/completions",
            json=data,
            timeout=300
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' not in result or not result['choices']:
                raise ValueError(f"Invalid API response structure: {result}")
            
            choice = result['choices'][0]
            
            if choice.get('finish_reason') == 'content_filter':
                raise ContentFilteredException("Batch translation content filtered by OpenAI safety system")
            
            if 'message' not in choice or 'content' not in choice['message']:
                raise ValueError(f"Invalid message structure in API response: {result}")
            
            translated_content = choice['message']['content'].strip()
            
            # è§£æç¿»è¯‘ç»“æœ
            if len(entries) == 1:
                # å•æ®µè½
                translated_texts = [translated_content]
            else:
                # å¤šæ®µè½ï¼ŒæŒ‰ %% åˆ†å‰²
                if '\n%%\n' in translated_content:
                    translated_texts = translated_content.split('\n%%\n')
                elif '%%' in translated_content:
                    translated_texts = translated_content.split('%%')
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†éš”ç¬¦ï¼Œå¯èƒ½æ˜¯å•ä¸ªç¿»è¯‘ç»“æœï¼ŒæŒ‰è¡Œæ•°åˆ†å‰²
                    lines = translated_content.split('\n')
                    if len(lines) >= len(entries):
                        translated_texts = lines[:len(entries)]
                    else:
                        translated_texts = [translated_content]  # ä½¿ç”¨æ•´ä¸ªç¿»è¯‘ä½œä¸ºç¬¬ä¸€ä¸ªç»“æœ
            
            # ç¡®ä¿ç¿»è¯‘ç»“æœæ•°é‡åŒ¹é…
            while len(translated_texts) < len(entries):
                translated_texts.append(entries[len(translated_texts)]['text'])  # ä½¿ç”¨åŸæ–‡å¡«å……
            translated_texts = translated_texts[:len(entries)]  # æˆªæ–­å¤šä½™çš„ç»“æœ
            
            # æ„å»ºæœ€ç»ˆç»“æœ
            translated_entries = []
            for i, entry in enumerate(entries):
                translated_text = translated_texts[i].strip() if i < len(translated_texts) else entry['text']
                if not translated_text:
                    translated_text = entry['text']  # å¦‚æœç¿»è¯‘ä¸ºç©ºï¼Œä½¿ç”¨åŸæ–‡
                
                translated_entries.append({
                    'id': entry['id'],
                    'timestamp': entry['timestamp'],
                    'text': f"{entry['text']}\n{translated_text}"
                })
            
            self.logger.info(f"Successfully translated {len(translated_entries)} entries via OpenAI paragraph batch")
            return translated_entries
                
        else:
            raise requests.exceptions.RequestException(f"OpenAI API error: {response.status_code} - {response.text}")
    
    def _translate_openai_multiple_batches(self, entries, max_chars=None, max_entries=None):
        """OpenAIå¤šæ‰¹æ¬¡ç¿»è¯‘ - ä½¿ç”¨æ®µè½åˆ†éš”ç¬¦æ–¹æ¡ˆ"""
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤é…ç½®å€¼
        if max_chars is None:
            max_chars = OPENAI_MAX_CHARS_PER_BATCH
        if max_entries is None:
            max_entries = OPENAI_MAX_ENTRIES_PER_BATCH
            
        all_translated = []
        batches = []
        current_batch = []
        current_chars = 0
        
        # æ„å»ºæ‰¹æ¬¡
        for entry in entries:
            entry_length = len(entry['text'])
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°æ‰¹æ¬¡
            if (len(current_batch) >= max_entries or 
                current_chars + entry_length > max_chars) and current_batch:
                batches.append(current_batch)
                current_batch = []
                current_chars = 0
            
            current_batch.append(entry)
            current_chars += entry_length
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch:
            batches.append(current_batch)
        
        self.logger.info(f"Split into {len(batches)} batches for OpenAI paragraph translation")
        
        # é€æ‰¹æ¬¡ç¿»è¯‘
        for i, batch in enumerate(batches):
            try:
                self.logger.info(f"Translating batch {i+1}/{len(batches)} with {len(batch)} entries")
                
                # ä½¿ç”¨å•æ‰¹æ¬¡ç¿»è¯‘å‡½æ•°
                translated_batch = self._translate_openai_batch(batch)
                all_translated.extend(translated_batch)
                
                # å‘å‡ºè¿›åº¦ä¿¡å· - ä½¿ç”¨æ­£ç¡®çš„è¿›åº¦æŠ¥å‘Šæ–¹æ³•
                progress = 72 + int((i + 1) / len(batches) * 8)
                self.report_progress(min(80, progress))
                
                # æ‰¹æ¬¡é—´é€‚å½“å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                if i < len(batches) - 1:
                    time.sleep(0.1)
                    
            except Exception as e:
                self.logger.error(f"Failed to translate batch {i+1}: {str(e)}")
                # å¦‚æœæ‰¹æ¬¡ç¿»è¯‘å¤±è´¥ï¼Œä¿ç•™åŸæ–‡
                failed_batch = []
                for entry in batch:
                    failed_batch.append({
                        'id': entry['id'],
                        'timestamp': entry['timestamp'],
                        'text': entry['text']  # ä¿æŒåŸæ–‡
                    })
                all_translated.extend(failed_batch)
        
        self.logger.info(f"Completed OpenAI paragraph translation: {len(all_translated)} entries")
        return all_translated
    
    def _batch_translate_with_google(self, entries):
        """ä½¿ç”¨Google Translateæ‰¹é‡ç¿»è¯‘æ‰€æœ‰å­—å¹•ï¼Œæ”¯æŒåˆ†æ‰¹å¤„ç†å¤§æ–‡æœ¬"""
        try:
            separator = "\n---SUBTITLE_SEPARATOR---\n"
            max_chars = 4500  # ç•™ä¸€äº›ä½™é‡ï¼Œé¿å…è¶…è¿‡5000å­—ç¬¦é™åˆ¶
            translated_entries = []
            
            # åˆ†æ‰¹å¤„ç†å­—å¹•æ¡ç›®
            current_batch = []
            current_length = 0
            batch_count = 0
            
            # å…ˆè®¡ç®—æ€»æ‰¹æ¬¡æ•°ä»¥ä¾¿æ˜¾ç¤ºè¿›åº¦
            total_batches = 1
            temp_length = 0
            for entry in entries:
                entry_length = len(entry['text']) + len(separator)
                if temp_length + entry_length > max_chars and temp_length > 0:
                    total_batches += 1
                    temp_length = entry_length
                else:
                    temp_length += entry_length
            
            for entry in entries:
                entry_text = entry['text']
                entry_length = len(entry_text) + len(separator)
                
                # å¦‚æœæ·»åŠ å½“å‰æ¡ç›®ä¼šè¶…è¿‡é™åˆ¶ï¼Œå…ˆå¤„ç†å½“å‰æ‰¹æ¬¡
                if current_length + entry_length > max_chars and current_batch:
                    batch_count += 1
                    self.logger.info(f"Processing Google Translate batch {batch_count}/{total_batches} ({len(current_batch)} entries, {current_length} chars)")
                    
                    # æ›´æ–°è¿›åº¦ (72% -> 80% çš„èŒƒå›´å†…)
                    progress = 72 + int((batch_count / total_batches) * 8)
                    self.report_progress(min(80, progress))
                    
                    batch_results = self._translate_google_batch(current_batch, separator)
                    translated_entries.extend(batch_results)
                    
                    # é‡ç½®æ‰¹æ¬¡
                    current_batch = []
                    current_length = 0
                
                current_batch.append(entry)
                current_length += entry_length
            
            # å¤„ç†æœ€åä¸€æ‰¹
            if current_batch:
                batch_count += 1
                self.logger.info(f"Processing final Google Translate batch {batch_count}/{total_batches} ({len(current_batch)} entries, {current_length} chars)")
                batch_results = self._translate_google_batch(current_batch, separator)
                translated_entries.extend(batch_results)
            
            self.logger.info(f"Successfully translated {len(translated_entries)} entries via Google Translate in {batch_count} batches")
            return translated_entries
            
        except Exception as e:
            self.logger.error(f"Google Translate batch translation failed: {str(e)}")
            raise
    
    def _translate_google_batch(self, entries, separator):
        """ç¿»è¯‘ä¸€ä¸ªæ‰¹æ¬¡çš„å­—å¹•æ¡ç›®"""
        # æå–æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬
        texts_to_translate = [entry['text'] for entry in entries]
        
        # ä½¿ç”¨åˆ†éš”ç¬¦å°†æ‰€æœ‰æ–‡æœ¬åˆå¹¶æˆä¸€ä¸ªå¤§å­—ç¬¦ä¸²
        combined_text = separator.join(texts_to_translate)
        
        # ä½¿ç”¨Deep Translatorè¿›è¡Œæ‰¹é‡ç¿»è¯‘
        translator = GoogleTranslator(source='auto', target='zh-CN')
        translated_combined = translator.translate(combined_text)
        
        if not translated_combined:
            raise ValueError("Empty response from Google Translate")
        
        # åˆ†å‰²ç¿»è¯‘ç»“æœ
        translated_texts = translated_combined.split(separator)
        
        # ç¡®ä¿ç¿»è¯‘ç»“æœæ•°é‡åŒ¹é…
        if len(translated_texts) != len(entries):
            self.logger.warning(f"Translation count mismatch: expected {len(entries)}, got {len(translated_texts)}")
            # å¡«å……ç¼ºå¤±çš„ç¿»è¯‘
            while len(translated_texts) < len(entries):
                translated_texts.append("")
            translated_texts = translated_texts[:len(entries)]
        
        # æ„å»ºç¿»è¯‘ç»“æœ
        batch_results = []
        for i, entry in enumerate(entries):
            translated_text = translated_texts[i].strip() if i < len(translated_texts) else ""
            if not translated_text:
                translated_text = entry['text']  # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡
            
            batch_results.append({
                'id': entry['id'],
                'timestamp': entry['timestamp'],
                'text': f"{entry['text']}\n{translated_text}"
            })
        
        return batch_results

    def burn_subtitles(self, subtitle_path, output_path):
        ffmpeg_path = self.get_ffmpeg_path()
        if not ffmpeg_path:
            error_msg = "Could not find ffmpeg."
            if getattr(sys, 'frozen', False):
                error_msg += " Application may not be properly installed or ffmpeg not bundled correctly."
                error_msg += f" Searched in: {sys.executable} directory and Contents/MacOS"
            else:
                error_msg += " Please install it first (e.g., brew install ffmpeg)."
            self.logger.error(error_msg)
            raise FileNotFoundError(error_msg)
            
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(subtitle_path):
            raise FileNotFoundError(f"Subtitle file not found: {subtitle_path}")
        
        # æ£€æŸ¥å­—å¹•æ–‡ä»¶æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å†…å®¹
        try:
            with open(subtitle_path, 'r', encoding='utf-8') as f:
                subtitle_content = f.read().strip()
                if not subtitle_content:
                    raise ValueError(f"Subtitle file is empty: {subtitle_path}")
        except Exception as e:
            raise ValueError(f"Error reading subtitle file {subtitle_path}: {str(e)}")
            
        try:
            # ä¼˜åŒ–çš„ç¡¬ä»¶åŠ é€Ÿå­—å¹•çƒ§å½•å‘½ä»¤ï¼Œæ›´æ¿€è¿›çš„å‹ç¼©
            cmd = [
                ffmpeg_path,
                "-hwaccel", "videotoolbox",
                "-i", self.video_path,
                "-vf", f"subtitles='{subtitle_path}':force_style='FontSize=16,PrimaryColour=&HFFFFFF,OutlineColour=&H000000,BorderStyle=4'",
                "-c:v", "h264_videotoolbox",
                "-b:v", "0",  # ä½¿ç”¨å˜åŠ¨æ¯”ç‰¹ç‡æ¨¡å¼
                "-q:v", "52", # VideoToolboxè´¨é‡å‚æ•°è°ƒæ•´ä¸º55ï¼Œæ›´æ¿€è¿›çš„å‹ç¼©
                "-c:a", "copy",
                "-movflags", "+faststart",  # ä¼˜åŒ–åœ¨çº¿æ’­æ”¾
                output_path,
                "-y"  # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            ]
            
            # ä½¿ç”¨ Popen æ¥ç›‘æ§è¿›åº¦
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                universal_newlines=True
            )
            
            # ç›‘æ§è¿›åº¦ (80% -> 100%)
            progress_start = 80
            progress_range = 20
            
            stderr_output = ""
            while True:
                output = process.stderr.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    stderr_output += output
                    # ç®€å•çš„è¿›åº¦ä¼°ç®—ï¼Œæ¯ç§’å¢åŠ ä¸€ç‚¹è¿›åº¦
                    current_progress = progress_start + min(progress_range, len(stderr_output) // 100)
                    if current_progress > progress_start:
                        self.report_progress(min(99, current_progress))
            
            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            return_code = process.poll()
            if return_code != 0:
                raise subprocess.CalledProcessError(return_code, cmd, stderr=stderr_output)
                
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
                raise RuntimeError("Video processing failed: output file is empty or missing")
            
            self.logger.info("Video processing completed successfully")
            return True
        except subprocess.CalledProcessError as e:
            error_msg = f"Error during FFmpeg processing: {e.stderr}"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)


# ===== å¤šè¿›ç¨‹æ”¯æŒå‡½æ•° =====

def process_video_worker(
    video_path: str,
    engine: str,
    api_settings: Dict[str, Any],
    cache_dir: str,
    progress_queue: mp.Queue,
    result_queue: mp.Queue,
    process_id: int
):
    """
    å¤šè¿›ç¨‹è§†é¢‘å¤„ç†å·¥ä½œå‡½æ•°
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        engine: ç¿»è¯‘å¼•æ“
        api_settings: APIè®¾ç½®
        cache_dir: ç¼“å­˜ç›®å½•
        progress_queue: è¿›åº¦æŠ¥å‘Šé˜Ÿåˆ—
        result_queue: ç»“æœé˜Ÿåˆ—
        process_id: è¿›ç¨‹ID
    """
    try:
        # åˆ›å»ºå¤„ç†å™¨å®ä¾‹ï¼ˆä¸ç»§æ‰¿QRunnableï¼Œç›´æ¥ä½¿ç”¨æ ¸å¿ƒåŠŸèƒ½ï¼‰
        processor = VideoProcessorForMultiprocess(
            video_path=video_path,
            engine=engine,
            api_settings=api_settings,
            cache_dir=cache_dir,
            progress_queue=progress_queue,
            process_id=process_id
        )
        
        # æ‰§è¡Œå¤„ç†
        result = processor.process()
        
        # å‘é€æˆåŠŸç»“æœ
        result_queue.put({
            'process_id': process_id,
            'video_path': video_path,
            'status': 'success',
            'result': result
        })
        
    except Exception as e:
        # å‘é€é”™è¯¯ç»“æœ
        result_queue.put({
            'process_id': process_id,
            'video_path': video_path,
            'status': 'error',
            'error': str(e)
        })


class VideoProcessorForMultiprocess:
    """ç®€åŒ–çš„è§†é¢‘å¤„ç†å™¨ï¼Œä¸“é—¨ç”¨äºå¤šè¿›ç¨‹ç¯å¢ƒ"""
    
    def __init__(self, video_path: str, engine: str, api_settings: Dict[str, Any], 
                 cache_dir: str, progress_queue: mp.Queue, process_id: int):
        self.video_path = video_path
        self.engine = engine
        self.api_settings = api_settings
        self.cache_dir = cache_dir
        self.progress_queue = progress_queue
        self.process_id = process_id
        self.base_name = os.path.basename(video_path)
        
        # åˆ›å»ºæ—¥å¿—å™¨å®ä¾‹
        self.logger = VideoLogger(cache_dir)
        
        # åˆ›å»ºç‹¬ç«‹çš„requestsä¼šè¯
        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {self.api_settings.get('api_key', '')}",
            "Content-Type": "application/json"
        })
        
        # é…ç½®è¿æ¥æ± 
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=5,
            pool_maxsize=10,
            max_retries=3,
            pool_block=False
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)
        
        # ç»§æ‰¿åŸæœ‰çš„ç³»ç»Ÿæ£€æµ‹é€»è¾‘
        self.use_hardware_accel = VideoProcessor._check_hardware_acceleration(self)
        self.is_apple_silicon = VideoProcessor._is_apple_silicon(self)
        
        # å¼€å§‹æ—¶é—´
        self.start_time = time.time()
    
    def report_progress(self, progress: int):
        """æŠ¥å‘Šè¿›åº¦"""
        try:
            elapsed = time.time() - self.start_time
            elapsed_str = self._format_elapsed_time(elapsed)
            
            self.progress_queue.put({
                'type': 'progress',
                'process_id': self.process_id,
                'video_path': self.video_path,
                'base_name': self.base_name,
                'progress': progress,
                'elapsed_time': elapsed_str
            }, block=False)
        except queue.Full:
            pass  # å¿½ç•¥é˜Ÿåˆ—æ»¡çš„æƒ…å†µï¼Œé¿å…é˜»å¡
    
    def report_status(self, status: str):
        """æŠ¥å‘ŠçŠ¶æ€"""
        try:
            self.progress_queue.put({
                'type': 'status',
                'process_id': self.process_id,
                'video_path': self.video_path,
                'base_name': self.base_name,
                'status': status
            }, block=False)
        except queue.Full:
            pass
    
    def _format_elapsed_time(self, elapsed_seconds: float) -> str:
        """æ ¼å¼åŒ–ç»è¿‡çš„æ—¶é—´ä¸º MM:SS æ ¼å¼"""
        minutes = int(elapsed_seconds // 60)
        seconds = int(elapsed_seconds % 60)
        return f"{minutes:02d}:{seconds:02d}"
    
    def process(self) -> Dict[str, Any]:
        """ä¸»å¤„ç†æµç¨‹ - å¤ç”¨åŸæœ‰VideoProcessorçš„æ–¹æ³•"""
        try:
            print(f"ğŸ¬ Process {self.process_id}: Starting to process {self.base_name}")
            
            # ä½¿ç”¨åŸæœ‰çš„get_cache_pathsé€»è¾‘
            cache_paths = self.get_cache_paths()
            
            # éŸ³é¢‘æå– (0-10%)
            self.report_status("Extracting audio...")
            self.report_progress(0)
            self.extract_audio(cache_paths['audio'])
            self.report_progress(10)
            
            # è¯­éŸ³è¯†åˆ« (10-70%)
            self.report_status("Recognizing speech...")
            self.generate_subtitles(cache_paths['audio'], cache_paths['srt'])
            self.report_progress(70)
            
            # å­—å¹•ç¿»è¯‘ (70-80%)
            self.report_status("Translating subtitles...")
            with open(cache_paths['srt'], "r", encoding="utf-8") as f:
                lines = f.readlines()
            translated_content = self.translate_subtitles(lines)
            
            if not translated_content or translated_content.strip() == "":
                self.report_status("Empty bilingual subtitles, skipping video synthesis")
                self.report_progress(100)
                return {'status': 'skipped', 'reason': 'empty_subtitles'}
            
            with open(cache_paths['bilingual_srt'], "w", encoding="utf-8") as f:
                f.write(translated_content)
            self.report_progress(80)
            
            # è§†é¢‘åˆæˆ (80-100%)
            self.report_status("Synthesizing video...")
            self.burn_subtitles(cache_paths['bilingual_srt'], cache_paths['output_video'])
            self.report_progress(100)
            self.report_status("Processing completed!")
            
            return {
                'status': 'completed',
                'output_path': cache_paths['output_video'],
                'cache_paths': cache_paths
            }
            
        except Exception as e:
            error_msg = f"Processing failed: {str(e)}"
            self.report_status(error_msg)
            raise RuntimeError(error_msg)
        finally:
            # æ¸…ç†èµ„æº
            try:
                if hasattr(self, 'session'):
                    self.session.close()
                    
                # æ¸…ç†æ—¥å¿—å¤„ç†å™¨
                if hasattr(self, 'logger'):
                    self.logger.cleanup()
            except Exception:
                pass
    
    # ä»¥ä¸‹æ–¹æ³•ç›´æ¥å¤ç”¨VideoProcessorçš„æ–¹æ³•ï¼Œé¿å…é‡å¤ä»£ç 
    def get_cache_paths(self):
        return VideoProcessor.get_cache_paths(self)
    
    def get_ffmpeg_path(self):
        return VideoProcessor.get_ffmpeg_path()
    
    def check_has_audio(self):
        return VideoProcessor.check_has_audio(self)
    
    def extract_audio(self, audio_path):
        return VideoProcessor.extract_audio(self, audio_path)
    
    def generate_subtitles(self, audio_path, srt_path):
        """ç”Ÿæˆå­—å¹• - åœ¨å­è¿›ç¨‹ä¸­åˆ›å»ºç‹¬ç«‹çš„è¯­éŸ³è¯†åˆ«å™¨"""
        try:
            # åœ¨å­è¿›ç¨‹ä¸­å¯¼å…¥å’Œåˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
            from core.speech_recognizer import SpeechRecognizer, SubtitleFormatter
            
            print(f"ğŸ™ï¸ Process {self.process_id}: Initializing speech recognizer...")
            
            # åˆ›å»ºè¿›ç¨‹ä¸“ç”¨çš„è¯­éŸ³è¯†åˆ«å™¨
            speech_recognizer = SpeechRecognizer(
                model_name="mlx-community/parakeet-tdt-0.6b-v2",
                fp32=False,
                local_attention=True,
                local_attention_context_size=256
            )
            
            self.report_progress(20)
            
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶å¤§å°
            if os.path.getsize(audio_path) < 1000:
                print(f"ğŸ™ï¸ Process {self.process_id}: Audio file is very small, creating empty subtitle")
                with open(srt_path, "w", encoding="utf-8") as f:
                    f.write("")
                return
            
            # è¿›åº¦å›è°ƒå‡½æ•°
            def progress_callback(current_chunk, total_chunks):
                if total_chunks > 0:
                    recognition_progress = (current_chunk / total_chunks) * 50
                    progress = 20 + recognition_progress
                    self.report_progress(min(70, int(progress)))
            
            # è½¬å½•
            result = speech_recognizer.transcribe(
                audio_path,
                chunk_duration=120.0,
                overlap_duration=15.0,
                progress_callback=progress_callback
            )
            
            self.report_progress(70)
            
            # ç”ŸæˆSRTæ ¼å¼
            srt_content = SubtitleFormatter.to_srt(result, highlight_words=False)
            
            with open(srt_path, "w", encoding="utf-8") as f:
                f.write(srt_content)
            
            segment_count = len(result.sentences)
            print(f"ğŸ™ï¸ Process {self.process_id}: Transcription completed, {segment_count} segments")
            
        except Exception as e:
            print(f"ğŸ™ï¸ Process {self.process_id}: Transcription failed: {str(e)}")
            raise RuntimeError(f"Transcription failed: {str(e)}")
    
    def translate_subtitles(self, lines):
        """ç¿»è¯‘å­—å¹• - å¤šè¿›ç¨‹ç‰ˆæœ¬ï¼Œä¸ä½¿ç”¨signals"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå­—å¹•æ–‡ä»¶
            if not lines or all(not line.strip() for line in lines):
                print(f"ğŸ™ï¸ Process {self.process_id}: Empty subtitle file detected, skipping translation")
                return ""
            
            entries = []
            current_id = None
            current_timestamp = ""
            current_text = []
            parsing_state = "id"  # å¯èƒ½çš„çŠ¶æ€: id, timestamp, text

            for line in lines:
                line = line.strip()
                if not line:  # ç©ºè¡Œè¡¨ç¤ºä¸€ä¸ªå­—å¹•æ¡ç›®ç»“æŸ
                    if current_id is not None and current_timestamp and current_text:
                        entries.append({
                            'id': current_id,
                            'timestamp': current_timestamp,
                            'text': '\n'.join(current_text)
                        })
                    # é‡ç½®çŠ¶æ€ä¸ºè§£ææ–°æ¡ç›®çš„ID
                    current_id = None
                    current_timestamp = ""
                    current_text = []
                    parsing_state = "id"
                    continue
                
                if parsing_state == "id" and line.isdigit():
                    current_id = int(line)
                    parsing_state = "timestamp"
                elif parsing_state == "timestamp" and '-->' in line:
                    current_timestamp = line
                    parsing_state = "text"
                elif parsing_state == "text":
                    current_text.append(line)

            # å¤„ç†æ–‡ä»¶æœ«å°¾å¯èƒ½å­˜åœ¨çš„æœ€åä¸€ä¸ªæ¡ç›®
            if current_id is not None and current_timestamp and current_text:
                entries.append({
                    'id': current_id,
                    'timestamp': current_timestamp,
                    'text': '\n'.join(current_text)
                })

            total_entries = len(entries)
            if total_entries == 0:
                print(f"âš ï¸ Process {self.process_id}: No valid subtitle entries found to translate")
                return ""
                
            print(f"ğŸ™ï¸ Process {self.process_id}: Starting batch translation of {total_entries} subtitle entries")
            
            # æ‰¹é‡ç¿»è¯‘æ‰€æœ‰å­—å¹• (70% -> 80%)
            self.report_progress(72)
            
            # ä½¿ç”¨è‡ªå·±çš„ç¿»è¯‘æ–¹æ³•è€Œä¸æ˜¯çˆ¶ç±»çš„
            if self.engine == "OpenAI Translate":
                translated_entries = self._batch_translate_with_openai_multiprocess(entries)
            else:  # Google Translation
                translated_entries = self._batch_translate_with_google_multiprocess(entries)
            
            self.report_progress(80)

            # Sort by ID to Ensure Correct Subtitle Ordering
            translated_entries.sort(key=lambda x: x['id'])

            # Construct Final Subtitle Content
            translated_content = ""
            for entry in translated_entries:
                translated_content += f"{entry['id']}\n{entry['timestamp']}\n{entry['text']}\n\n"

            return translated_content

        except Exception as e:
            error_msg = f"Translation Process Failed: {str(e)}"
            print(f"âŒ Process {self.process_id}: {error_msg}")
            raise RuntimeError(error_msg)
    
    def _batch_translate_with_openai_multiprocess(self, entries):
        """å¤šè¿›ç¨‹ç‰ˆæœ¬çš„OpenAIç¿»è¯‘"""
        try:
            from config import OPENAI_MODEL, OPENAI_CUSTOM_PROMPT, OPENAI_MAX_CHARS_PER_BATCH, OPENAI_MAX_ENTRIES_PER_BATCH
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            OPENAI_MAX_CHARS_PER_BATCH = 8000
            OPENAI_MAX_ENTRIES_PER_BATCH = 50
            OPENAI_MODEL = "gpt-3.5-turbo"
            OPENAI_CUSTOM_PROMPT = "You are a professional translator. Translate the following text to Chinese, maintaining the original meaning and tone."
        
        try:
            # ä»é…ç½®æ–‡ä»¶è·å–æ‰¹å¤„ç†å‚æ•°
            max_chars_per_batch = self.api_settings.get("max_chars_per_batch", OPENAI_MAX_CHARS_PER_BATCH)
            max_entries_per_batch = self.api_settings.get("max_entries_per_batch", OPENAI_MAX_ENTRIES_PER_BATCH)
            
            total_chars = sum(len(entry['text']) for entry in entries)
            
            if total_chars <= max_chars_per_batch and len(entries) <= max_entries_per_batch:
                # å†…å®¹è¾ƒå°‘ï¼Œä½¿ç”¨å•ä¸€æ‰¹é‡è¯·æ±‚
                print(f"ğŸ™ï¸ Process {self.process_id}: Content size {total_chars} chars, {len(entries)} entries - using single batch request")
                return self._translate_openai_batch_multiprocess(entries)
            else:
                # å†…å®¹è¿‡å¤šï¼Œéœ€è¦åˆ†æ‰¹å¤„ç†
                print(f"ğŸ™ï¸ Process {self.process_id}: Content size {total_chars} chars, {len(entries)} entries - using multiple batch processing")
                return self._translate_openai_multiple_batches_multiprocess(entries, max_chars_per_batch, max_entries_per_batch)
                
        except Exception as e:
            print(f"âŒ Process {self.process_id}: OpenAI batch translation failed: {str(e)}")
            raise
    
    def _translate_openai_batch_multiprocess(self, entries):
        """å¤šè¿›ç¨‹ç‰ˆæœ¬çš„OpenAIå•æ‰¹æ¬¡ç¿»è¯‘"""
        try:
            from config import OPENAI_MODEL, OPENAI_CUSTOM_PROMPT
        except ImportError:
            OPENAI_MODEL = "gpt-3.5-turbo"
            OPENAI_CUSTOM_PROMPT = "You are a professional translator. Translate the following text to Chinese, maintaining the original meaning and tone."
        
        # æ„å»ºç¿»è¯‘æ–‡æœ¬ - ä½¿ç”¨ %% åˆ†éš”ç¬¦
        if len(entries) == 1:
            # å•æ®µè½ï¼Œç›´æ¥ç¿»è¯‘
            text_to_translate = entries[0]['text']
        else:
            # å¤šæ®µè½ï¼Œä½¿ç”¨ %% åˆ†éš”
            texts = [entry['text'] for entry in entries]
            text_to_translate = '\n%%\n'.join(texts)
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è‡ªå®šä¹‰prompt
        system_prompt = OPENAI_CUSTOM_PROMPT
        user_prompt = f"Translate to Chinese (output translation only):\n\n{text_to_translate}"
        
        data = {
            "model": self.api_settings.get("model", OPENAI_MODEL),
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0,
            "max_tokens": 8000  # é€‚ä¸­çš„tokené™åˆ¶
        }

        response = self.session.post(
            f"{self.api_settings['base_url']}/v1/chat/completions",
            json=data,
            timeout=300
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' not in result or not result['choices']:
                raise ValueError(f"Invalid API response structure: {result}")
            
            choice = result['choices'][0]
            
            if choice.get('finish_reason') == 'content_filter':
                raise Exception("Batch translation content filtered by OpenAI safety system")
            
            if 'message' not in choice or 'content' not in choice['message']:
                raise ValueError(f"Invalid message structure in API response: {result}")
            
            translated_content = choice['message']['content'].strip()
            
            # è§£æç¿»è¯‘ç»“æœ
            if len(entries) == 1:
                # å•æ®µè½
                translated_texts = [translated_content]
            else:
                # å¤šæ®µè½ï¼ŒæŒ‰ %% åˆ†å‰²
                if '\n%%\n' in translated_content:
                    translated_texts = translated_content.split('\n%%\n')
                elif '%%' in translated_content:
                    translated_texts = translated_content.split('%%')
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†éš”ç¬¦ï¼Œå¯èƒ½æ˜¯å•ä¸ªç¿»è¯‘ç»“æœï¼ŒæŒ‰è¡Œæ•°åˆ†å‰²
                    lines = translated_content.split('\n')
                    if len(lines) >= len(entries):
                        translated_texts = lines[:len(entries)]
                    else:
                        translated_texts = [translated_content]  # ä½¿ç”¨æ•´ä¸ªç¿»è¯‘ä½œä¸ºç¬¬ä¸€ä¸ªç»“æœ
            
            # ç¡®ä¿ç¿»è¯‘ç»“æœæ•°é‡åŒ¹é…
            while len(translated_texts) < len(entries):
                translated_texts.append(entries[len(translated_texts)]['text'])  # ä½¿ç”¨åŸæ–‡å¡«å……
            translated_texts = translated_texts[:len(entries)]  # æˆªæ–­å¤šä½™çš„ç»“æœ
            
            # æ„å»ºæœ€ç»ˆç»“æœ
            translated_entries = []
            for i, entry in enumerate(entries):
                translated_text = translated_texts[i].strip() if i < len(translated_texts) else entry['text']
                if not translated_text:
                    translated_text = entry['text']  # å¦‚æœç¿»è¯‘ä¸ºç©ºï¼Œä½¿ç”¨åŸæ–‡
                
                translated_entries.append({
                    'id': entry['id'],
                    'timestamp': entry['timestamp'],
                    'text': f"{entry['text']}\n{translated_text}"
                })
            
            print(f"ğŸ™ï¸ Process {self.process_id}: Successfully translated {len(translated_entries)} entries via OpenAI")
            return translated_entries
                
        else:
            raise Exception(f"OpenAI API error: {response.status_code} - {response.text}")
    
    def _translate_openai_multiple_batches_multiprocess(self, entries, max_chars, max_entries):
        """å¤šè¿›ç¨‹ç‰ˆæœ¬çš„OpenAIå¤šæ‰¹æ¬¡ç¿»è¯‘"""
        all_translated = []
        batches = []
        current_batch = []
        current_chars = 0
        
        # æ„å»ºæ‰¹æ¬¡
        for entry in entries:
            entry_length = len(entry['text'])
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°æ‰¹æ¬¡
            if (len(current_batch) >= max_entries or 
                current_chars + entry_length > max_chars) and current_batch:
                batches.append(current_batch)
                current_batch = []
                current_chars = 0
            
            current_batch.append(entry)
            current_chars += entry_length
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch:
            batches.append(current_batch)
        
        print(f"ğŸ™ï¸ Process {self.process_id}: Split into {len(batches)} batches for OpenAI translation")
        
        # é€æ‰¹æ¬¡ç¿»è¯‘
        for i, batch in enumerate(batches):
            try:
                print(f"ğŸ™ï¸ Process {self.process_id}: Translating batch {i+1}/{len(batches)} with {len(batch)} entries")
                
                # ä½¿ç”¨å•æ‰¹æ¬¡ç¿»è¯‘å‡½æ•°
                translated_batch = self._translate_openai_batch_multiprocess(batch)
                all_translated.extend(translated_batch)
                
                # å‘å‡ºè¿›åº¦ä¿¡å·
                progress = 72 + int((i + 1) / len(batches) * 8)
                self.report_progress(min(80, progress))
                
                # æ‰¹æ¬¡é—´é€‚å½“å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                if i < len(batches) - 1:
                    time.sleep(0.1)
                    
            except Exception as e:
                print(f"âŒ Process {self.process_id}: Failed to translate batch {i+1}: {str(e)}")
                # å¦‚æœæ‰¹æ¬¡ç¿»è¯‘å¤±è´¥ï¼Œä¿ç•™åŸæ–‡
                failed_batch = []
                for entry in batch:
                    failed_batch.append({
                        'id': entry['id'],
                        'timestamp': entry['timestamp'],
                        'text': entry['text']  # ä¿æŒåŸæ–‡
                    })
                all_translated.extend(failed_batch)
        
        print(f"ğŸ™ï¸ Process {self.process_id}: Completed OpenAI translation: {len(all_translated)} entries")
        return all_translated
    
    def _batch_translate_with_google_multiprocess(self, entries):
        """å¤šè¿›ç¨‹ç‰ˆæœ¬çš„Googleç¿»è¯‘"""
        try:
            separator = "\n---SUBTITLE_SEPARATOR---\n"
            max_chars = 4500  # ç•™ä¸€äº›ä½™é‡ï¼Œé¿å…è¶…è¿‡5000å­—ç¬¦é™åˆ¶
            translated_entries = []
            
            # åˆ†æ‰¹å¤„ç†å­—å¹•æ¡ç›®
            current_batch = []
            current_length = 0
            batch_count = 0
            
            # å…ˆè®¡ç®—æ€»æ‰¹æ¬¡æ•°ä»¥ä¾¿æ˜¾ç¤ºè¿›åº¦
            total_batches = 1
            temp_length = 0
            for entry in entries:
                entry_length = len(entry['text']) + len(separator)
                if temp_length + entry_length > max_chars and temp_length > 0:
                    total_batches += 1
                    temp_length = entry_length
                else:
                    temp_length += entry_length
            
            for entry in entries:
                entry_text = entry['text']
                entry_length = len(entry_text) + len(separator)
                
                # å¦‚æœæ·»åŠ å½“å‰æ¡ç›®ä¼šè¶…è¿‡é™åˆ¶ï¼Œå…ˆå¤„ç†å½“å‰æ‰¹æ¬¡
                if current_length + entry_length > max_chars and current_batch:
                    batch_count += 1
                    print(f"ğŸ™ï¸ Process {self.process_id}: Processing Google Translate batch {batch_count}/{total_batches} ({len(current_batch)} entries, {current_length} chars)")
                    
                    # æ›´æ–°è¿›åº¦ (72% -> 80% çš„èŒƒå›´å†…)
                    progress = 72 + int((batch_count / total_batches) * 8)
                    self.report_progress(min(80, progress))
                    
                    batch_results = self._translate_google_batch_multiprocess(current_batch, separator)
                    translated_entries.extend(batch_results)
                    
                    # é‡ç½®æ‰¹æ¬¡
                    current_batch = []
                    current_length = 0
                
                current_batch.append(entry)
                current_length += entry_length
            
            # å¤„ç†æœ€åä¸€æ‰¹
            if current_batch:
                batch_count += 1
                print(f"ğŸ™ï¸ Process {self.process_id}: Processing final Google Translate batch {batch_count}/{total_batches} ({len(current_batch)} entries, {current_length} chars)")
                batch_results = self._translate_google_batch_multiprocess(current_batch, separator)
                translated_entries.extend(batch_results)
            
            print(f"ğŸ™ï¸ Process {self.process_id}: Successfully translated {len(translated_entries)} entries via Google Translate in {batch_count} batches")
            return translated_entries
            
        except Exception as e:
            print(f"âŒ Process {self.process_id}: Google Translate batch translation failed: {str(e)}")
            raise
    
    def _translate_google_batch_multiprocess(self, entries, separator):
        """å¤šè¿›ç¨‹ç‰ˆæœ¬çš„Googleæ‰¹æ¬¡ç¿»è¯‘"""
        # æå–æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬
        texts_to_translate = [entry['text'] for entry in entries]
        
        # ä½¿ç”¨åˆ†éš”ç¬¦å°†æ‰€æœ‰æ–‡æœ¬åˆå¹¶æˆä¸€ä¸ªå¤§å­—ç¬¦ä¸²
        combined_text = separator.join(texts_to_translate)
        
        # ä½¿ç”¨Deep Translatorè¿›è¡Œæ‰¹é‡ç¿»è¯‘
        from deep_translator import GoogleTranslator
        translator = GoogleTranslator(source='auto', target='zh-CN')
        translated_combined = translator.translate(combined_text)
        
        if not translated_combined:
            raise ValueError("Empty response from Google Translate")
        
        # åˆ†å‰²ç¿»è¯‘ç»“æœ
        translated_texts = translated_combined.split(separator)
        
        # ç¡®ä¿ç¿»è¯‘ç»“æœæ•°é‡åŒ¹é…
        if len(translated_texts) != len(entries):
            print(f"âš ï¸ Process {self.process_id}: Translation count mismatch: expected {len(entries)}, got {len(translated_texts)}")
            # å¡«å……ç¼ºå¤±çš„ç¿»è¯‘
            while len(translated_texts) < len(entries):
                translated_texts.append("")
            translated_texts = translated_texts[:len(entries)]
        
        # æ„å»ºç¿»è¯‘ç»“æœ
        batch_results = []
        for i, entry in enumerate(entries):
            translated_text = translated_texts[i].strip() if i < len(translated_texts) else ""
            if not translated_text:
                translated_text = entry['text']  # å¦‚æœç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡
            
            batch_results.append({
                'id': entry['id'],
                'timestamp': entry['timestamp'],
                'text': f"{entry['text']}\n{translated_text}"
            })
        
        return batch_results
    
    def burn_subtitles(self, subtitle_path, output_path):
        return VideoProcessor.burn_subtitles(self, subtitle_path, output_path)


class MultiprocessVideoManager:
    """å¤šè¿›ç¨‹è§†é¢‘å¤„ç†ç®¡ç†å™¨"""
    
    def __init__(self, max_processes: Optional[int] = None):
        self.processes = []
        self.active_processes = {}  # è·Ÿè¸ªæ´»åŠ¨è¿›ç¨‹ {process_id: process_info}
        self.pending_tasks = []  # ç­‰å¾…å¤„ç†çš„ä»»åŠ¡é˜Ÿåˆ—
        self.progress_queue = mp.Queue()
        self.result_queue = mp.Queue()
        self.is_processing = False
        self.next_process_id = 0
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¿›ç¨‹æ•°ï¼Œæˆ–è€…ä¼ å…¥çš„å‚æ•°
        if max_processes is not None:
            self.max_processes = max_processes
        else:
            # ä»configå¯¼å…¥è¿›ç¨‹æ•°é…ç½®
            self.max_processes = MAX_PROCESSES
        
        print(f"ğŸ”§ MultiprocessVideoManager initialized with max_processes={self.max_processes}")
    
    def _is_apple_silicon(self) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯Apple Silicon"""
        if platform.system() != 'Darwin':
            return False
        try:
            result = subprocess.run(['sysctl', '-n', 'hw.optional.arm64'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0 and result.stdout.strip() == '1'
        except Exception:
            return False
    
    def start_processing(self, video_tasks: list):
        """
        å¼€å§‹å¤šè¿›ç¨‹å¤„ç†
        
        Args:
            video_tasks: è§†é¢‘ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å« (video_path, engine, api_settings, cache_dir)
        """
        if self.is_processing:
            raise RuntimeError("å·²æœ‰å¤„ç†ä»»åŠ¡åœ¨è¿›è¡Œä¸­")
        
        self.is_processing = True
        self.processes = []
    
    def submit_video(self, video_path: str, engine: str, api_settings: Dict[str, Any], cache_dir: str) -> int:
        """
        æäº¤å•ä¸ªè§†é¢‘è¿›è¡Œå¤„ç†
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            engine: ç¿»è¯‘å¼•æ“
            api_settings: APIè®¾ç½®
            cache_dir: ç¼“å­˜ç›®å½•
            
        Returns:
            int: è¿›ç¨‹IDï¼ˆä»»åŠ¡IDï¼‰
        """
        if not self.is_processing:
            self.is_processing = True
        
        # åˆ›å»ºä»»åŠ¡ä¿¡æ¯
        task_info = {
            'task_id': self.next_process_id,
            'video_path': video_path,
            'engine': engine,
            'api_settings': api_settings,
            'cache_dir': cache_dir,
            'status': 'pending'  # pending, running, completed, failed
        }
        
        self.next_process_id += 1
        
        # å°†ä»»åŠ¡æ·»åŠ åˆ°å¾…å¤„ç†é˜Ÿåˆ—
        self.pending_tasks.append(task_info)
        print(f"ğŸ“ Added task {task_info['task_id']} for {os.path.basename(video_path)} to queue")
        
        # å°è¯•å¯åŠ¨æ–°ä»»åŠ¡
        self._try_start_next_tasks()
        
        return task_info['task_id']
    
    def _try_start_next_tasks(self):
        """å°è¯•å¯åŠ¨ä¸‹ä¸€ä¸ªä»»åŠ¡ï¼ˆå¦‚æœæœ‰ç©ºé—²è¿›ç¨‹æ§½ä½ï¼‰"""
        # æ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹
        self._cleanup_finished_processes()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºé—²æ§½ä½å’Œå¾…å¤„ç†ä»»åŠ¡
        while len(self.active_processes) < self.max_processes and self.pending_tasks:
            task_info = self.pending_tasks.pop(0)  # å–å‡ºç¬¬ä¸€ä¸ªä»»åŠ¡
            self._start_task(task_info)
    
    def _start_task(self, task_info: Dict[str, Any]):
        """å¯åŠ¨å•ä¸ªä»»åŠ¡"""
        process_id = task_info['task_id']
        
        # åˆ›å»ºå¹¶å¯åŠ¨è¿›ç¨‹
        process = mp.Process(
            target=process_video_worker,
            args=(
                task_info['video_path'],
                task_info['engine'],
                task_info['api_settings'],
                task_info['cache_dir'],
                self.progress_queue,
                self.result_queue,
                process_id
            )
        )
        process.start()
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task_info['status'] = 'running'
        task_info['process'] = process
        task_info['completed'] = False
        
        # ä¿å­˜è¿›ç¨‹ä¿¡æ¯
        self.processes.append(task_info)
        self.active_processes[process_id] = task_info
        
        print(f"ğŸš€ Started process {process_id} for {os.path.basename(task_info['video_path'])} (active: {len(self.active_processes)}/{self.max_processes}, pending: {len(self.pending_tasks)})")
    
    def _cleanup_finished_processes(self):
        """æ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹å¹¶å¯åŠ¨æ–°ä»»åŠ¡"""
        finished_process_ids = []
        
        for process_id, proc_info in self.active_processes.items():
            if not proc_info['process'].is_alive():
                finished_process_ids.append(process_id)
                # ç¡®ä¿è¿›ç¨‹æ­£ç¡®ç»“æŸ
                proc_info['process'].join(timeout=1)
                proc_info['completed'] = True
                proc_info['status'] = 'completed'
                print(f"ğŸ§¹ Cleaned up finished process {process_id} for {os.path.basename(proc_info['video_path'])}")
        
        # ä»æ´»åŠ¨è¿›ç¨‹å­—å…¸ä¸­ç§»é™¤å·²å®Œæˆçš„è¿›ç¨‹
        for process_id in finished_process_ids:
            if process_id in self.active_processes:
                del self.active_processes[process_id]
    
    def get_progress_updates(self) -> list:
        """è·å–æ‰€æœ‰è¿›åº¦æ›´æ–°"""
        # é¦–å…ˆæ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹å¹¶å°è¯•å¯åŠ¨æ–°ä»»åŠ¡
        self._cleanup_finished_processes()
        self._try_start_next_tasks()
        
        updates = []
        while True:
            try:
                update = self.progress_queue.get_nowait()
                updates.append(update)
            except queue.Empty:
                break
        return updates
    
    def get_results(self) -> list:
        """è·å–æ‰€æœ‰å®Œæˆçš„ç»“æœ"""
        results = []
        while True:
            try:
                result = self.result_queue.get_nowait()
                results.append(result)
            except queue.Empty:
                break
        return results
    
    def is_all_complete(self) -> bool:
        """æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡æ˜¯å¦å®Œæˆï¼ˆåŒ…æ‹¬é˜Ÿåˆ—ä¸­çš„ï¼‰"""
        if not self.processes and not self.pending_tasks:
            return True
        
        # æ¸…ç†å·²å®Œæˆçš„è¿›ç¨‹å¹¶å°è¯•å¯åŠ¨æ–°ä»»åŠ¡
        self._cleanup_finished_processes()
        self._try_start_next_tasks()
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ´»åŠ¨è¿›ç¨‹æˆ–å¾…å¤„ç†ä»»åŠ¡
        return len(self.active_processes) == 0 and len(self.pending_tasks) == 0
    
    def process_videos(self, video_paths: List[str], engine: str, api_settings: Dict[str, Any], cache_dir: str) -> List[int]:
        """
        æ‰¹é‡å¤„ç†è§†é¢‘æ–‡ä»¶
        
        Args:
            video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            engine: ç¿»è¯‘å¼•æ“
            api_settings: APIè®¾ç½®
            cache_dir: ç¼“å­˜ç›®å½•
            
        Returns:
            List[int]: ä»»åŠ¡IDåˆ—è¡¨
        """
        if not video_paths:
            return []
        
        task_ids = []
        print(f"ğŸ“‹ Submitting {len(video_paths)} videos for processing (max concurrent: {self.max_processes})")
        
        for video_path in video_paths:
            if os.path.exists(video_path):
                task_id = self.submit_video(video_path, engine, api_settings, cache_dir)
                task_ids.append(task_id)
                print(f"   Added: {os.path.basename(video_path)} (Task ID: {task_id})")
            else:
                print(f"âš ï¸ Video file not found: {video_path}")
        
        print(f"ğŸ“Š Queue Status: {len(self.active_processes)} running, {len(self.pending_tasks)} pending")
        return task_ids
    
    def get_active_process_count(self) -> int:
        """è·å–å½“å‰æ´»åŠ¨è¿›ç¨‹æ•°é‡"""
        self._cleanup_finished_processes()
        return len(self.active_processes)
    
    def get_total_process_count(self) -> int:
        """è·å–æ€»è¿›ç¨‹æ•°é‡ï¼ˆåŒ…æ‹¬å·²å®Œæˆçš„ï¼‰"""
        return len(self.processes)
    
    def stop_all(self):
        """åœæ­¢æ‰€æœ‰è¿›ç¨‹"""
        print("ğŸ›‘ Stopping all processes...")
        
        # åœæ­¢æ‰€æœ‰æ´»åŠ¨è¿›ç¨‹
        for process_id, proc_info in self.active_processes.items():
            if proc_info['process'].is_alive():
                print(f"ğŸ›‘ Terminating process {process_id}")
                proc_info['process'].terminate()
                proc_info['process'].join(timeout=5)
                if proc_info['process'].is_alive():
                    print(f"ğŸ›‘ Force killing process {process_id}")
                    proc_info['process'].kill()
                proc_info['completed'] = True
        
        # æ¸…ç©ºæ´»åŠ¨è¿›ç¨‹å­—å…¸å’Œå¾…å¤„ç†ä»»åŠ¡
        self.active_processes.clear()
        self.pending_tasks.clear()
        self.is_processing = False
        print(f"ğŸ›‘ All processes stopped. Cleared {len(self.pending_tasks)} pending tasks.")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("ğŸ§¹ Cleaning up multiprocess manager...")
        
        self.stop_all()
        
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.progress_queue.empty():
            try:
                self.progress_queue.get_nowait()
            except queue.Empty:
                break
        
        while not self.result_queue.empty():
            try:
                self.result_queue.get_nowait()
            except queue.Empty:
                break
        
        print("ğŸ§¹ Multiprocess manager cleanup completed")




