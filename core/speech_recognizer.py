"""
è¯­éŸ³è¯†åˆ«æ¨¡å— - åŸºäº Parakeet MLX
ä» check.py æå–æ ¸å¿ƒåŠŸèƒ½ï¼Œå»é™¤ CLI ç›¸å…³å†…å®¹
"""
import json
import threading
from typing import Any, Dict, Optional, Callable
from mlx.core import bfloat16, float32
from parakeet_mlx import AlignedResult, AlignedSentence, AlignedToken, from_pretrained

from utils.logger import VideoLogger


class SpeechRecognizer:
    """è¯­éŸ³è¯†åˆ«ç±»ï¼Œå°è£… Parakeet MLX æ¨¡å‹ - å•ä¾‹æ¨¡å¼ä»¥é¿å…å¤šçº¿ç¨‹å†²çª"""
    
    _instance = None
    _lock = threading.Lock()
    _model_lock = threading.Lock()  # æ¨¡å‹è®¿é—®é”
    
    def __new__(cls, *args, **kwargs):
        """å•ä¾‹æ¨¡å¼å®ç°"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    print("ğŸ™ï¸ Creating new SpeechRecognizer singleton instance")
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        else:
            print("ğŸ™ï¸ Reusing existing SpeechRecognizer singleton instance")
        return cls._instance
    
    def __init__(self, 
                 model_name: str = "mlx-community/parakeet-tdt-0.6b-v2",
                 fp32: bool = False,
                 local_attention: bool = False,
                 local_attention_context_size: int = 256,
                 logger: Optional[VideoLogger] = None,
                 download_callback: Optional[Callable[[str], None]] = None,
                 progress_callback: Optional[Callable[[int, float, float, float], None]] = None,
                 status_callback: Optional[Callable[[str], None]] = None):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        
        Args:
            model_name: æ¨¡å‹åç§°
            fp32: æ˜¯å¦ä½¿ç”¨FP32ç²¾åº¦
            local_attention: æ˜¯å¦ä½¿ç”¨å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶
            local_attention_context_size: å±€éƒ¨æ³¨æ„åŠ›ä¸Šä¸‹æ–‡å¤§å°
            logger: æ—¥å¿—è®°å½•å™¨
            download_callback: ä¸‹è½½å¼€å§‹å›è°ƒ
            progress_callback: ä¸‹è½½è¿›åº¦å›è°ƒ (percentage, downloaded_mb, total_mb, speed_mbps)
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒ
        """
        # é¿å…é‡å¤åˆå§‹åŒ–
        if self._initialized:
            return
            
        self.model_name = model_name
        self.fp32 = fp32
        self.local_attention = local_attention
        self.local_attention_context_size = local_attention_context_size
        self.logger = logger
        self.download_callback = download_callback
        self.progress_callback = progress_callback
        self.status_callback = status_callback
        self._model = None
        self._initialized = True
        
    def _load_model(self):
        """åŠ è½½æ¨¡å‹ - çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬"""
        # åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
        if self._model is not None:
            return
            
        with self._model_lock:
            # å†æ¬¡æ£€æŸ¥ï¼Œé˜²æ­¢åœ¨ç­‰å¾…é”çš„è¿‡ç¨‹ä¸­å…¶ä»–çº¿ç¨‹å·²ç»åŠ è½½äº†æ¨¡å‹
            if self._model is not None:
                return
                
            if self.logger:
                self.logger.info(f"Loading model: {self.model_name}")
                
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦éœ€è¦ä¸‹è½½ï¼ˆç®€å•æ–¹å¼ï¼šæ£€æŸ¥ç¼“å­˜ç›®å½•ï¼‰
            needs_download = self._check_if_model_needs_download()
            
            # åªæœ‰åœ¨éœ€è¦ä¸‹è½½æ—¶æ‰é€šçŸ¥UIæ˜¾ç¤ºä¸‹è½½å¯¹è¯æ¡†
            if needs_download and self.download_callback:
                self.download_callback(self.model_name)
                
            if needs_download and self.status_callback:
                self.status_callback("Initializing model download...")
            elif self.status_callback:
                self.status_callback("Loading cached model...")
                
            try:
                # Parakeet MLX ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œä½†æ²¡æœ‰è¿›åº¦å›è°ƒ
                # æˆ‘ä»¬æä¾›ä¸€ä¸ªç®€å•çš„çŠ¶æ€æ›´æ–°
                if needs_download and self.status_callback:
                    self.status_callback(f"Downloading {self.model_name}...")
                    
                self._model = from_pretrained(
                    self.model_name, 
                    dtype=bfloat16 if not self.fp32 else float32
                )
                
                if self.local_attention:
                    self._model.encoder.set_attention_model(
                        "rel_pos_local_attn",
                        (self.local_attention_context_size, self.local_attention_context_size),
                    )
                    
                if self.logger:
                    self.logger.info("Model loaded successfully")
                    
                if self.status_callback:
                    self.status_callback("Model loaded successfully!")
                        
                # é€šçŸ¥ä¸‹è½½å®Œæˆï¼ˆå¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼‰
                if needs_download and self.progress_callback:
                    self.progress_callback(100, 0, 0, 0)  # 100% å®Œæˆ
                        
            except Exception as e:
                error_msg = f"Error loading model {self.model_name}: {e}"
                if self.logger:
                    self.logger.error(error_msg)
                raise RuntimeError(error_msg)
    
    def _check_if_model_needs_download(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦éœ€è¦ä¸‹è½½"""
        try:
            import os
            from huggingface_hub import hf_hub_download, try_to_load_from_cache
            
            # æ£€æŸ¥Hugging Faceç¼“å­˜ä¸­æ˜¯å¦å­˜åœ¨æ¨¡å‹æ–‡ä»¶
            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ£€æŸ¥ï¼Œå®é™…çš„æ¨¡å‹æ–‡ä»¶å¯èƒ½æœ‰å¤šä¸ª
            try:
                # å°è¯•ä»ç¼“å­˜åŠ è½½ï¼Œå¦‚æœä¸å­˜åœ¨ä¼šè¿”å›None
                cached_file = try_to_load_from_cache(
                    repo_id=self.model_name,
                    filename="config.json"  # æ£€æŸ¥é…ç½®æ–‡ä»¶
                )
                return cached_file is None
            except:
                # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œå‡è®¾éœ€è¦ä¸‹è½½
                return True
        except ImportError:
            # å¦‚æœæ²¡æœ‰huggingface_hubï¼Œå‡è®¾éœ€è¦ä¸‹è½½
            return True
    
    def transcribe(self, 
                   audio_path: str,
                   chunk_duration: Optional[float] = 120.0,
                   overlap_duration: float = 15.0,
                   progress_callback: Optional[Callable[[int, int], None]] = None) -> AlignedResult:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶ - çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            chunk_duration: åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸åˆ†å—
            overlap_duration: é‡å æ—¶é•¿ï¼ˆç§’ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current_chunk, total_chunks)
            
        Returns:
            AlignedResult: è½¬å½•ç»“æœ
        """
        self._load_model()
        
        if self.logger:
            self.logger.info(f"Starting transcription of: {audio_path}")
            
        try:
            # ä½¿ç”¨æ¨¡å‹é”ç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªè½¬å½•ä»»åŠ¡åœ¨è¿è¡Œ
            if self.logger:
                self.logger.info("Acquiring transcription lock...")
            
            with self._model_lock:
                if self.logger:
                    self.logger.info("Transcription lock acquired, starting transcription...")
                
                result = self._model.transcribe(
                    audio_path,
                    dtype=bfloat16 if not self.fp32 else float32,
                    chunk_duration=chunk_duration,
                    overlap_duration=overlap_duration,
                    chunk_callback=progress_callback
                )
            
            if self.logger:
                self.logger.info(f"Transcription completed for: {audio_path}")
                
            return result
            
        except Exception as e:
            error_msg = f"Error transcribing file {audio_path}: {e}"
            if self.logger:
                self.logger.error(error_msg)
            raise RuntimeError(error_msg)
    
    @classmethod
    def cleanup_singleton(cls):
        """æ¸…ç†å•ä¾‹å®ä¾‹ - ç”¨äºåº”ç”¨ç¨‹åºé€€å‡ºæ—¶"""
        with cls._lock:
            if cls._instance is not None:
                try:
                    if hasattr(cls._instance, '_model') and cls._instance._model is not None:
                        # MLX æ¨¡å‹ä¼šè‡ªåŠ¨æ¸…ç†ï¼Œæˆ‘ä»¬åªéœ€è¦å°†å¼•ç”¨è®¾ä¸ºNone
                        cls._instance._model = None
                except Exception as e:
                    print(f"Error cleaning up SpeechRecognizer singleton: {e}")
                finally:
                    cls._instance = None


class SubtitleFormatter:
    """å­—å¹•æ ¼å¼åŒ–å™¨"""
    
    @staticmethod
    def format_timestamp(seconds: float, always_include_hours: bool = True, decimal_marker: str = ",") -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
        assert seconds >= 0
        milliseconds = round(seconds * 1000.0)

        hours = milliseconds // 3_600_000
        milliseconds %= 3_600_000

        minutes = milliseconds // 60_000
        milliseconds %= 60_000

        seconds = milliseconds // 1_000
        milliseconds %= 1_000

        hours_marker = f"{hours:02d}:" if always_include_hours or hours > 0 else ""
        return (
            f"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}"
        )

    @staticmethod
    def to_txt(result: AlignedResult) -> str:
        """æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬"""
        return result.text.strip()

    @staticmethod
    def to_srt(result: AlignedResult, highlight_words: bool = False) -> str:
        """
        æ ¼å¼åŒ–ä¸ºSRTå­—å¹•æ–‡ä»¶
        
        Args:
            result: è½¬å½•ç»“æœ
            highlight_words: æ˜¯å¦é«˜äº®å•è¯
            
        Returns:
            str: SRTæ ¼å¼å­—å¹•å†…å®¹
        """
        srt_content = []
        entry_index = 1
        
        if highlight_words:
            for sentence in result.sentences:
                for i, token in enumerate(sentence.tokens):
                    start_time = SubtitleFormatter.format_timestamp(token.start, decimal_marker=",")
                    end_time = SubtitleFormatter.format_timestamp(
                        token.end
                        if token == sentence.tokens[-1]
                        else sentence.tokens[i + 1].start,
                        decimal_marker=",",
                    )

                    text = ""
                    for j, inner_token in enumerate(sentence.tokens):
                        if i == j:
                            text += inner_token.text.replace(
                                inner_token.text.strip(),
                                f"<u>{inner_token.text.strip()}</u>",
                            )
                        else:
                            text += inner_token.text
                    text = text.strip()

                    srt_content.append(f"{entry_index}")
                    srt_content.append(f"{start_time} --> {end_time}")
                    srt_content.append(text)
                    srt_content.append("")
                    entry_index += 1
        else:
            for sentence in result.sentences:
                start_time = SubtitleFormatter.format_timestamp(sentence.start, decimal_marker=",")
                end_time = SubtitleFormatter.format_timestamp(sentence.end, decimal_marker=",")
                text = sentence.text.strip()

                srt_content.append(f"{entry_index}")
                srt_content.append(f"{start_time} --> {end_time}")
                srt_content.append(text)
                srt_content.append("")
                entry_index += 1

        return "\n".join(srt_content)

    @staticmethod
    def to_vtt(result: AlignedResult, highlight_words: bool = False) -> str:
        """
        æ ¼å¼åŒ–ä¸ºVTTå­—å¹•æ–‡ä»¶
        
        Args:
            result: è½¬å½•ç»“æœ
            highlight_words: æ˜¯å¦é«˜äº®å•è¯
            
        Returns:
            str: VTTæ ¼å¼å­—å¹•å†…å®¹
        """
        vtt_content = ["WEBVTT", ""]
        
        if highlight_words:
            for sentence in result.sentences:
                for i, token in enumerate(sentence.tokens):
                    start_time = SubtitleFormatter.format_timestamp(token.start, decimal_marker=".")
                    end_time = SubtitleFormatter.format_timestamp(
                        token.end
                        if token == sentence.tokens[-1]
                        else sentence.tokens[i + 1].start,
                        decimal_marker=".",
                    )

                    text_line = ""
                    for j, inner_token in enumerate(sentence.tokens):
                        if i == j:
                            text_line += inner_token.text.replace(
                                inner_token.text.strip(),
                                f"<b>{inner_token.text.strip()}</b>",
                            )
                        else:
                            text_line += inner_token.text
                    text_line = text_line.strip()

                    vtt_content.append(f"{start_time} --> {end_time}")
                    vtt_content.append(text_line)
                    vtt_content.append("")
        else:
            for sentence in result.sentences:
                start_time = SubtitleFormatter.format_timestamp(sentence.start, decimal_marker=".")
                end_time = SubtitleFormatter.format_timestamp(sentence.end, decimal_marker=".")
                text_line = sentence.text.strip()

                vtt_content.append(f"{start_time} --> {end_time}")
                vtt_content.append(text_line)
                vtt_content.append("")

        return "\n".join(vtt_content)

    @staticmethod
    def _aligned_token_to_dict(token: AlignedToken) -> Dict[str, Any]:
        """å°†å¯¹é½çš„tokenè½¬æ¢ä¸ºå­—å…¸"""
        return {
            "text": token.text,
            "start": round(token.start, 3),
            "end": round(token.end, 3),
            "duration": round(token.duration, 3),
        }

    @staticmethod
    def _aligned_sentence_to_dict(sentence: AlignedSentence) -> Dict[str, Any]:
        """å°†å¯¹é½çš„å¥å­è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "text": sentence.text,
            "start": round(sentence.start, 3),
            "end": round(sentence.end, 3),
            "duration": round(sentence.duration, 3),
            "tokens": [SubtitleFormatter._aligned_token_to_dict(token) for token in sentence.tokens],
        }

    @staticmethod
    def to_json(result: AlignedResult) -> str:
        """
        æ ¼å¼åŒ–ä¸ºJSON
        
        Args:
            result: è½¬å½•ç»“æœ
            
        Returns:
            str: JSONæ ¼å¼å†…å®¹
        """
        output_dict = {
            "text": result.text,
            "sentences": [
                SubtitleFormatter._aligned_sentence_to_dict(sentence) 
                for sentence in result.sentences
            ],
        }
        return json.dumps(output_dict, indent=2, ensure_ascii=False)
