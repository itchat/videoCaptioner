"""
è¯­éŸ³è¯†åˆ«æ¨¡å— - åŸºäº Parakeet MLX
æ”¯æŒå¤šè¿›ç¨‹å’Œå¤šçº¿ç¨‹å®‰å…¨æ“ä½œ
"""
import json
import threading
import os
import math
import tempfile
import subprocess
from typing import Any, Dict, Optional, Callable
from mlx.core import bfloat16, float32
from parakeet_mlx import AlignedResult, AlignedSentence, AlignedToken, from_pretrained
from utils.logger import VideoLogger


class SpeechRecognizer:
    """è¯­éŸ³è¯†åˆ«ç±»ï¼Œå°è£… Parakeet MLX æ¨¡å‹ - æ”¯æŒå¤šè¿›ç¨‹å’Œå¤šçº¿ç¨‹å®‰å…¨"""
    
    # è¿›ç¨‹çº§åˆ«çš„å®ä¾‹å­—å…¸ï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½æœ‰è‡ªå·±çš„å®ä¾‹
    _instances = {}
    _lock = threading.Lock()
    _model_lock = threading.Lock()  # æ¨¡å‹è®¿é—®é”
    
    def __new__(cls, *args, **kwargs):
        """è¿›ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼å®ç° - æ¯ä¸ªè¿›ç¨‹éƒ½æœ‰è‡ªå·±çš„å®ä¾‹"""
        current_pid = os.getpid()
        
        if current_pid not in cls._instances:
            with cls._lock:
                if current_pid not in cls._instances:
                    print(f"ğŸ™ï¸ Creating new SpeechRecognizer instance for process {current_pid}")
                    instance = super().__new__(cls)
                    instance._initialized = False
                    instance._process_id = current_pid
                    cls._instances[current_pid] = instance
                else:
                    print(f"ğŸ™ï¸ Reusing SpeechRecognizer instance for process {current_pid}")
        else:
            print(f"ğŸ™ï¸ Reusing existing SpeechRecognizer instance for process {current_pid}")
            
        return cls._instances[current_pid]
    
    def __init__(self, 
                 model_name: str = "mlx-community/parakeet-tdt-0.6b-v2",
                 fp32: bool = False,
                 local_attention: bool = False,
                 local_attention_context_size: int = 256,
                 logger: Optional[VideoLogger] = None,
                 download_callback: Optional[Callable[[str], None]] = None,
                 progress_callback: Optional[Callable[[int, float, float, float], None]] = None,
                 status_callback: Optional[Callable[[str], None]] = None):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨ï¼ˆè¿›ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼ï¼‰
        
        Args:
            model_name: æ¨¡å‹åç§°
            fp32: æ˜¯å¦ä½¿ç”¨FP32ç²¾åº¦
            local_attention: æ˜¯å¦ä½¿ç”¨å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶
            local_attention_context_size: å±€éƒ¨æ³¨æ„åŠ›ä¸Šä¸‹æ–‡å¤§å°
            logger: æ—¥å¿—è®°å½•å™¨
            download_callback: ä¸‹è½½å¼€å§‹å›è°ƒ
            progress_callback: ä¸‹è½½è¿›åº¦å›è°ƒ (percentage, downloaded_mb, total_mb, speed_mbps)
            status_callback: çŠ¶æ€æ›´æ–°å›è°ƒ
        """
        # é¿å…é‡å¤åˆå§‹åŒ–
        if self._initialized:
            return
            
        self.model_name = model_name
        self.fp32 = fp32
        self.local_attention = local_attention
        self.local_attention_context_size = local_attention_context_size
        self.logger = logger
        self.download_callback = download_callback
        self.progress_callback = progress_callback
        self.status_callback = status_callback
        self._model = None
        self._initialized = True
        
        print(f"ğŸ™ï¸ SpeechRecognizer initialized for process {self._process_id}")
        
    def _load_model(self):
        """åŠ è½½æ¨¡å‹ - è¿›ç¨‹å’Œçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼Œé˜²æ­¢å¤šè¿›ç¨‹é‡å¤ä¸‹è½½"""
        # åŒé‡æ£€æŸ¥é”å®šæ¨¡å¼
        if self._model is not None:
            return
            
        with self._model_lock:
            # å†æ¬¡æ£€æŸ¥ï¼Œé˜²æ­¢åœ¨ç­‰å¾…é”çš„è¿‡ç¨‹ä¸­å…¶ä»–çº¿ç¨‹å·²ç»åŠ è½½äº†æ¨¡å‹
            if self._model is not None:
                return
                
            if self.logger:
                self.logger.info(f"Process {self._process_id}: Loading model: {self.model_name}")
                
            try:
                # ä½¿ç”¨æ–‡ä»¶é”é˜²æ­¢è¿›ç¨‹é—´é‡å¤ä¸‹è½½ï¼ˆä»…åœ¨æ”¯æŒçš„å¹³å°ä¸Šï¼‰
                import tempfile
                try:
                    import fcntl
                    fcntl_available = True
                except ImportError:
                    fcntl_available = False
                    print(f"âš ï¸ Process {self._process_id}: fcntl not available on this platform, skipping file locking")
                
                lock_file_path = os.path.join(tempfile.gettempdir(), f"parakeet_download_{self.model_name.replace('/', '_')}.lock")
                
                if fcntl_available:
                    try:
                        # åˆ›å»ºè¿›ç¨‹é—´é”æ–‡ä»¶
                        with open(lock_file_path, 'w') as lock_file:
                            try:
                                # å°è¯•è·å–ç‹¬å é”
                                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                                print(f"ğŸ”’ Process {self._process_id}: Acquired download lock")
                                
                                # å†æ¬¡æ£€æŸ¥æ¨¡å‹æ˜¯å¦éœ€è¦ä¸‹è½½ï¼ˆåœ¨é”å†…é‡æ–°æ£€æŸ¥ï¼‰
                                needs_download = self._check_if_model_needs_download()
                                
                                # åªæœ‰åœ¨éœ€è¦ä¸‹è½½æ—¶æ‰é€šçŸ¥UIæ˜¾ç¤ºä¸‹è½½å¯¹è¯æ¡†
                                if needs_download and self.download_callback:
                                    self.download_callback(self.model_name)
                                    
                                if needs_download and self.status_callback:
                                    self.status_callback("Initializing model download...")
                                elif self.status_callback:
                                    self.status_callback("Loading cached model...")
                                    
                                # ä½¿ç”¨æ–°çš„ parakeet_mlx API
                                if needs_download and self.status_callback:
                                    self.status_callback(f"Downloading {self.model_name}...")
                                    
                                # åŠ è½½æ¨¡å‹
                                print(f"ğŸ“¥ Process {self._process_id}: Loading model from {'cache' if not needs_download else 'download'}")
                                self._model = from_pretrained(self.model_name)
                                
                                # é‡Šæ”¾é”ï¼ˆå‡½æ•°ç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾ï¼‰
                                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                                print(f"ğŸ”“ Process {self._process_id}: Released download lock")
                                
                            except IOError:
                                # æ— æ³•è·å–é”ï¼Œè¯´æ˜å…¶ä»–è¿›ç¨‹æ­£åœ¨ä¸‹è½½
                                print(f"â³ Process {self._process_id}: Another process is downloading, waiting...")
                                if self.status_callback:
                                    self.status_callback("Another process is downloading the model, please wait...")
                                
                                # é˜»å¡ç­‰å¾…é”ï¼ˆå…¶ä»–è¿›ç¨‹ä¸‹è½½å®Œæˆï¼‰
                                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
                                print(f"âœ… Process {self._process_id}: Download completed by other process, loading cached model")
                                
                                if self.status_callback:
                                    self.status_callback("Loading cached model...")
                                    
                                # ç›´æ¥åŠ è½½å·²ç¼“å­˜çš„æ¨¡å‹
                                self._model = from_pretrained(self.model_name)
                                
                                # é‡Šæ”¾é”
                                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                                
                    except Exception as e:
                        print(f"âš ï¸ Process {self._process_id}: File lock failed, falling back to direct loading: {e}")
                        # æ–‡ä»¶é”å¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆ
                        needs_download = self._check_if_model_needs_download()
                        
                        if needs_download and self.download_callback:
                            self.download_callback(self.model_name)
                            
                        if needs_download and self.status_callback:
                            self.status_callback("Initializing model download...")
                        elif self.status_callback:
                            self.status_callback("Loading cached model...")
                            
                        self._model = from_pretrained(self.model_name)
                else:
                    # fcntlä¸å¯ç”¨ï¼Œç›´æ¥åŠ è½½æ¨¡å‹
                    print(f"ğŸ“¥ Process {self._process_id}: Loading model directly (no file locking)")
                    needs_download = self._check_if_model_needs_download()
                    
                    if needs_download and self.download_callback:
                        self.download_callback(self.model_name)
                        
                    if needs_download and self.status_callback:
                        self.status_callback("Initializing model download...")
                    elif self.status_callback:
                        self.status_callback("Loading cached model...")
                        
                    self._model = from_pretrained(self.model_name)
                    
                # é…ç½®æ¨¡å‹å‚æ•°
                try:
                    if hasattr(self._model, 'set_dtype'):
                        dtype = float32 if self.fp32 else bfloat16
                        self._model.set_dtype(dtype)
                        print(f"ğŸ™ï¸ Process {self._process_id}: Model dtype set to {dtype}")
                    else:
                        print(f"ğŸ™ï¸ Process {self._process_id}: Model does not support set_dtype method")
                except Exception as e:
                    print(f"âš ï¸ Process {self._process_id}: Failed to set model dtype: {e}")
                
                try:
                    if self.local_attention and hasattr(self._model, 'set_local_attention'):
                        self._model.set_local_attention(
                            enabled=True,
                            context_size=self.local_attention_context_size
                        )
                        print(f"ğŸ™ï¸ Process {self._process_id}: Local attention enabled with context size {self.local_attention_context_size}")
                    else:
                        print(f"ğŸ™ï¸ Process {self._process_id}: Model does not support set_local_attention method")
                except Exception as e:
                    print(f"âš ï¸ Process {self._process_id}: Failed to set local attention: {e}")
                    
                if self.logger:
                    self.logger.info(f"Process {self._process_id}: Model loaded successfully")
                    
                if self.status_callback:
                    self.status_callback("Model loaded successfully!")
                    
            except Exception as e:
                error_msg = f"Process {self._process_id}: Error loading model {self.model_name}: {e}"
                if self.logger:
                    self.logger.error(error_msg)
                raise RuntimeError(error_msg)
    
    def _check_if_model_needs_download(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦éœ€è¦ä¸‹è½½ - æ”¹è¿›ç‰ˆæœ¬ï¼Œæ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶"""
        try:
            import os
            from huggingface_hub import try_to_load_from_cache
            
            # æ£€æŸ¥MLXæ¨¡å‹çš„å…³é”®æ–‡ä»¶æ˜¯å¦å·²ç¼“å­˜
            # æ ¹æ®å®é™…æ¨¡å‹ç»“æ„è°ƒæ•´æ£€æŸ¥çš„æ–‡ä»¶åˆ—è¡¨
            essential_files = [
                "config.json",           # æ¨¡å‹é…ç½®
                "model.safetensors",     # ä¸»è¦çš„æ¨¡å‹æƒé‡æ–‡ä»¶
            ]
            
            # å¯é€‰æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨æ›´å¥½ï¼Œä½†ä¸æ˜¯å¿…éœ€çš„ï¼‰
            optional_files = [
                "tokenizer.json",        # tokenizeré…ç½®
                "preprocessor_config.json"  # é¢„å¤„ç†å™¨é…ç½®
            ]
            
            print(f"ğŸ” Process {self._process_id}: Checking cache for model {self.model_name}")
            
            # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
            for filename in essential_files:
                try:
                    cached_file = try_to_load_from_cache(
                        repo_id=self.model_name,
                        filename=filename
                    )
                    if cached_file is None:
                        print(f"âŒ Process {self._process_id}: Missing essential cached file: {filename}")
                        return True
                    else:
                        print(f"âœ… Process {self._process_id}: Found essential cached file: {filename}")
                except Exception as e:
                    print(f"âš ï¸ Process {self._process_id}: Error checking {filename}: {e}")
                    return True
            
            # æ£€æŸ¥å¯é€‰æ–‡ä»¶ï¼ˆä»…ç”¨äºä¿¡æ¯æ˜¾ç¤ºï¼‰
            for filename in optional_files:
                try:
                    cached_file = try_to_load_from_cache(
                        repo_id=self.model_name,
                        filename=filename
                    )
                    if cached_file is None:
                        print(f"â„¹ï¸ Process {self._process_id}: Optional file not cached: {filename}")
                    else:
                        print(f"âœ… Process {self._process_id}: Found optional cached file: {filename}")
                except Exception as e:
                    print(f"â„¹ï¸ Process {self._process_id}: Optional file check failed for {filename}: {e}")
            
            print(f"âœ… Process {self._process_id}: All essential files found in cache, no download needed")
            return False
            
        except ImportError:
            print(f"âš ï¸ Process {self._process_id}: huggingface_hub not available, assuming download needed")
            return True
        except Exception as e:
            print(f"âš ï¸ Process {self._process_id}: Cache check failed: {e}, assuming download needed")
            return True
    
    def transcribe(self, 
                   audio_path: str,
                   chunk_duration: Optional[float] = 120.0,
                   overlap_duration: float = 15.0,
                   progress_callback: Optional[Callable[[int, int], None]] = None) -> AlignedResult:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶ - æ”¯æŒåˆ†å—å¤„ç†å’Œè¿›ç¨‹å®‰å…¨
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            chunk_duration: åˆ†å—æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸åˆ†å—
            overlap_duration: é‡å æ—¶é•¿ï¼ˆç§’ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (current_chunk, total_chunks)
            
        Returns:
            AlignedResult: è½¬å½•ç»“æœ
        """
        self._load_model()
        
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Audio file not found: {audio_path}")
        
        if self.logger:
            self.logger.info(f"Process {self._process_id}: Starting transcription of: {audio_path}")
            
        try:
            # ä½¿ç”¨æ¨¡å‹é”ç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªè½¬å½•ä»»åŠ¡åœ¨è¿è¡Œ
            if self.logger:
                self.logger.info(f"Process {self._process_id}: Acquiring transcription lock...")
            
            with self._model_lock:
                if self.logger:
                    self.logger.info(f"Process {self._process_id}: Transcription lock acquired, starting transcription...")
                
                # å¦‚æœæ²¡æœ‰æŒ‡å®šåˆ†å—æ—¶é•¿æˆ–è€…éŸ³é¢‘è¾ƒçŸ­ï¼Œç›´æ¥è½¬å½•
                if chunk_duration is None:
                    result = self._transcribe_chunk(audio_path)
                else:
                    # è·å–éŸ³é¢‘æ—¶é•¿
                    audio_duration = self._get_audio_duration(audio_path)
                    
                    if audio_duration <= chunk_duration:
                        # éŸ³é¢‘è¾ƒçŸ­ï¼Œç›´æ¥å¤„ç†
                        if progress_callback:
                            progress_callback(0, 1)
                        
                        result = self._transcribe_chunk(audio_path)
                        
                        if progress_callback:
                            progress_callback(1, 1)
                    else:
                        # éŸ³é¢‘è¾ƒé•¿ï¼Œåˆ†å—å¤„ç†
                        result = self._transcribe_with_chunks(
                            audio_path, 
                            audio_duration,
                            chunk_duration, 
                            overlap_duration, 
                            progress_callback
                        )
            
            if self.logger:
                self.logger.info(f"Process {self._process_id}: Transcription completed for: {audio_path}")
                
            return result
            
        except Exception as e:
            error_msg = f"Process {self._process_id}: Error transcribing file {audio_path}: {e}"
            if self.logger:
                self.logger.error(error_msg)
            raise RuntimeError(error_msg)
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            # ä½¿ç”¨ffprobeè·å–éŸ³é¢‘æ—¶é•¿
            cmd = [
                'ffprobe', '-v', 'quiet', '-show_entries', 'format=duration',
                '-of', 'csv=p=0', audio_path
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                return float(result.stdout.strip())
            else:
                # å›é€€æ–¹æ¡ˆï¼šå‡è®¾æ—¶é•¿
                file_size = os.path.getsize(audio_path)
                estimated_duration = file_size / (16000 * 2)  # 16kHz, 16-bit
                print(f"âš ï¸ Process {self._process_id}: Could not get exact duration, estimating {estimated_duration:.2f}s")
                return estimated_duration
        except Exception:
            # é»˜è®¤æ—¶é•¿
            return 60.0
    
    def _transcribe_chunk(self, audio_path: str) -> AlignedResult:
        """è½¬å½•å•ä¸ªéŸ³é¢‘å—"""
        try:
            # ä½¿ç”¨æ¨¡å‹å¤„ç†éŸ³é¢‘ - ç§»é™¤processorå‚æ•°ï¼Œå› ä¸ºæ–°ç‰ˆAPIä¸æ”¯æŒ
            result = self._model.transcribe(audio_path)
            return result
        except Exception as e:
            print(f"âŒ Process {self._process_id}: Chunk transcription failed: {str(e)}")
            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ - ä½¿ç”¨æ­£ç¡®çš„æ„é€ å‡½æ•°å‚æ•°
            return AlignedResult(text="", sentences=[])
    
    def _transcribe_with_chunks(self, 
                               audio_path: str,
                               audio_duration: float,
                               chunk_duration: float,
                               overlap_duration: float,
                               progress_callback: Optional[Callable[[int, int], None]] = None) -> AlignedResult:
        """åˆ†å—è½¬å½•é•¿éŸ³é¢‘"""
        
        # è®¡ç®—åˆ†å—å‚æ•°
        step_duration = chunk_duration - overlap_duration
        total_chunks = max(1, math.ceil((audio_duration - overlap_duration) / step_duration))
        
        print(f"ğŸ™ï¸ Process {self._process_id}: Processing {total_chunks} chunks (chunk: {chunk_duration}s, overlap: {overlap_duration}s)")
        
        all_sentences = []
        all_words = []
        
        for chunk_idx in range(total_chunks):
            try:
                # è®¡ç®—å½“å‰å—çš„æ—¶é—´èŒƒå›´
                start_time = chunk_idx * step_duration
                end_time = min(start_time + chunk_duration, audio_duration)
                
                print(f"ğŸ™ï¸ Process {self._process_id}: Processing chunk {chunk_idx + 1}/{total_chunks} ({start_time:.1f}s - {end_time:.1f}s)")
                
                # æå–éŸ³é¢‘å—
                chunk_path = self._extract_audio_chunk(audio_path, start_time, end_time)
                
                if chunk_path:
                    # è½¬å½•éŸ³é¢‘å—
                    chunk_result = self._transcribe_chunk(chunk_path)
                    
                    # è°ƒæ•´æ—¶é—´æˆ³å¹¶åˆå¹¶ç»“æœ
                    self._merge_chunk_result(
                        chunk_result, 
                        all_sentences,
                        start_time,
                        overlap_duration if chunk_idx > 0 else 0.0
                    )
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.unlink(chunk_path)
                    except Exception:
                        pass
                
                # æŠ¥å‘Šè¿›åº¦
                if progress_callback:
                    progress_callback(chunk_idx + 1, total_chunks)
                    
            except Exception as e:
                print(f"âš ï¸ Process {self._process_id}: Failed to process chunk {chunk_idx + 1}: {str(e)}")
                continue
        
        # åˆ›å»ºæœ€ç»ˆç»“æœ - ä½¿ç”¨æ­£ç¡®çš„æ„é€ å‡½æ•°å‚æ•°
        # åˆå¹¶æ‰€æœ‰å¥å­çš„æ–‡æœ¬
        combined_text = " ".join(sentence.text for sentence in all_sentences)
        final_result = AlignedResult(text=combined_text, sentences=all_sentences)
        print(f"ğŸ™ï¸ Process {self._process_id}: Transcription completed: {len(all_sentences)} sentences")
        
        return final_result
    
    def _extract_audio_chunk(self, audio_path: str, start_time: float, end_time: float) -> Optional[str]:
        """æå–éŸ³é¢‘å—"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                chunk_path = tmp_file.name
            
            # ä½¿ç”¨ffmpegæå–éŸ³é¢‘å—
            cmd = [
                'ffmpeg', '-y', '-i', audio_path,
                '-ss', str(start_time),
                '-t', str(end_time - start_time),
                '-ac', '1', '-ar', '16000',
                chunk_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and os.path.exists(chunk_path) and os.path.getsize(chunk_path) > 0:
                return chunk_path
            else:
                print(f"âš ï¸ Process {self._process_id}: Failed to extract audio chunk: {result.stderr}")
                try:
                    os.unlink(chunk_path)
                except Exception:
                    pass
                return None
                
        except Exception as e:
            print(f"âš ï¸ Process {self._process_id}: Audio chunk extraction error: {str(e)}")
            return None
    
    def _merge_chunk_result(self, 
                           chunk_result: AlignedResult,
                           all_sentences: list,
                           time_offset: float,
                           overlap_duration: float):
        """åˆå¹¶å—ç»“æœåˆ°æ€»ç»“æœä¸­"""
        if not chunk_result or not chunk_result.sentences:
            return
        
        # å¤„ç†å¥å­
        for sentence in chunk_result.sentences:
            # å¤„ç†å¥å­ä¸­çš„è¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            adjusted_tokens = []
            if hasattr(sentence, 'words') and sentence.words:
                for word in sentence.words:
                    adjusted_word = AlignedToken(
                        text=word.text,
                        start=word.start + time_offset,
                        end=word.end + time_offset,
                        id=getattr(word, 'id', 0),
                        duration=(word.end + time_offset) - (word.start + time_offset)
                    )
                    adjusted_tokens.append(adjusted_word)
            elif hasattr(sentence, 'tokens') and sentence.tokens:
                # å…¼å®¹ tokens å­—æ®µ
                for token in sentence.tokens:
                    adjusted_token = AlignedToken(
                        text=token.text,
                        start=token.start + time_offset,
                        end=token.end + time_offset,
                        id=getattr(token, 'id', 0),
                        duration=(token.end + time_offset) - (token.start + time_offset)
                    )
                    adjusted_tokens.append(adjusted_token)
            
            # è°ƒæ•´æ—¶é—´æˆ³ - ä¼ å…¥tokenså‚æ•°
            adjusted_sentence = AlignedSentence(
                text=sentence.text,
                start=sentence.start + time_offset,
                end=sentence.end + time_offset,
                tokens=adjusted_tokens
            )
            
            # è·³è¿‡é‡å éƒ¨åˆ†çš„å†…å®¹ï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªå—ï¼‰
            if time_offset == 0 or adjusted_sentence.start >= time_offset + overlap_duration:
                all_sentences.append(adjusted_sentence)

    @classmethod
    def cleanup_singleton(cls):
        """æ¸…ç†å•ä¾‹å®ä¾‹ - ç”¨äºåº”ç”¨ç¨‹åºé€€å‡ºæ—¶ï¼Œæ”¯æŒå¤šè¿›ç¨‹"""
        current_pid = os.getpid()
        with cls._lock:
            if current_pid in cls._instances:
                try:
                    instance = cls._instances[current_pid]
                    if hasattr(instance, '_model') and instance._model is not None:
                        # MLX æ¨¡å‹ä¼šè‡ªåŠ¨æ¸…ç†ï¼Œæˆ‘ä»¬åªéœ€è¦å°†å¼•ç”¨è®¾ä¸ºNone
                        instance._model = None
                    print(f"ğŸ™ï¸ Cleaned up SpeechRecognizer for process {current_pid}")
                except Exception as e:
                    print(f"Error cleaning up SpeechRecognizer for process {current_pid}: {e}")
                finally:
                    del cls._instances[current_pid]
    
    @classmethod
    def cleanup_all_instances(cls):
        """æ¸…ç†æ‰€æœ‰è¿›ç¨‹çš„å®ä¾‹ - ç”¨äºå®Œå…¨é€€å‡ºåº”ç”¨ç¨‹åºæ—¶"""
        with cls._lock:
            for pid, instance in list(cls._instances.items()):
                try:
                    if hasattr(instance, '_model') and instance._model is not None:
                        instance._model = None
                    print(f"ğŸ™ï¸ Cleaned up SpeechRecognizer for process {pid}")
                except Exception as e:
                    print(f"Error cleaning up SpeechRecognizer for process {pid}: {e}")
            cls._instances.clear()
            print("ğŸ™ï¸ All SpeechRecognizer instances cleaned up")


class SubtitleFormatter:
    """å­—å¹•æ ¼å¼åŒ–å™¨"""
    
    @staticmethod
    def format_timestamp(seconds: float, always_include_hours: bool = True, decimal_marker: str = ",") -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
        assert seconds >= 0
        milliseconds = round(seconds * 1000.0)

        hours = milliseconds // 3_600_000
        milliseconds %= 3_600_000

        minutes = milliseconds // 60_000
        milliseconds %= 60_000

        seconds = milliseconds // 1_000
        milliseconds %= 1_000

        hours_marker = f"{hours:02d}:" if always_include_hours or hours > 0 else ""
        return (
            f"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}"
        )

    @staticmethod
    def to_txt(result: AlignedResult) -> str:
        """æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬"""
        return result.text.strip()

    @staticmethod
    def to_srt(result: AlignedResult, highlight_words: bool = False) -> str:
        """
        æ ¼å¼åŒ–ä¸ºSRTå­—å¹•æ–‡ä»¶
        
        Args:
            result: è½¬å½•ç»“æœ
            highlight_words: æ˜¯å¦é«˜äº®å•è¯
            
        Returns:
            str: SRTæ ¼å¼å­—å¹•å†…å®¹
        """
        # å¤„ç†ç©ºç»“æœ
        if not result or not result.sentences:
            return ""
            
        srt_content = []
        entry_index = 1
        
        if highlight_words:
            for sentence in result.sentences:
                # æ£€æŸ¥å¥å­æ˜¯å¦æœ‰tokenså±æ€§
                if hasattr(sentence, 'tokens') and sentence.tokens:
                    for i, token in enumerate(sentence.tokens):
                        start_time = SubtitleFormatter.format_timestamp(token.start, decimal_marker=",")
                        end_time = SubtitleFormatter.format_timestamp(
                            token.end
                            if token == sentence.tokens[-1]
                            else sentence.tokens[i + 1].start,
                            decimal_marker=",",
                        )

                        text = ""
                        for j, inner_token in enumerate(sentence.tokens):
                            if i == j:
                                text += inner_token.text.replace(
                                    inner_token.text.strip(),
                                    f"<u>{inner_token.text.strip()}</u>",
                                )
                            else:
                                text += inner_token.text
                        text = text.strip()

                        srt_content.append(f"{entry_index}")
                        srt_content.append(f"{start_time} --> {end_time}")
                        srt_content.append(text)
                        srt_content.append("")
                        entry_index += 1
                else:
                    # å¦‚æœæ²¡æœ‰tokensï¼Œç›´æ¥ä½¿ç”¨å¥å­çº§åˆ«çš„æ—¶é—´æˆ³
                    start_time = SubtitleFormatter.format_timestamp(sentence.start, decimal_marker=",")
                    end_time = SubtitleFormatter.format_timestamp(sentence.end, decimal_marker=",")
                    text = sentence.text.strip()

                    srt_content.append(f"{entry_index}")
                    srt_content.append(f"{start_time} --> {end_time}")
                    srt_content.append(text)
                    srt_content.append("")
                    entry_index += 1
        else:
            for sentence in result.sentences:
                start_time = SubtitleFormatter.format_timestamp(sentence.start, decimal_marker=",")
                end_time = SubtitleFormatter.format_timestamp(sentence.end, decimal_marker=",")
                text = sentence.text.strip()

                srt_content.append(f"{entry_index}")
                srt_content.append(f"{start_time} --> {end_time}")
                srt_content.append(text)
                srt_content.append("")
                entry_index += 1

        return "\n".join(srt_content)

    @staticmethod
    def to_vtt(result: AlignedResult, highlight_words: bool = False) -> str:
        """
        æ ¼å¼åŒ–ä¸ºVTTå­—å¹•æ–‡ä»¶
        
        Args:
            result: è½¬å½•ç»“æœ
            highlight_words: æ˜¯å¦é«˜äº®å•è¯
            
        Returns:
            str: VTTæ ¼å¼å­—å¹•å†…å®¹
        """
        vtt_content = ["WEBVTT", ""]
        
        if highlight_words:
            for sentence in result.sentences:
                # æ£€æŸ¥å¥å­æ˜¯å¦æœ‰tokenså±æ€§
                if hasattr(sentence, 'tokens') and sentence.tokens:
                    for i, token in enumerate(sentence.tokens):
                        start_time = SubtitleFormatter.format_timestamp(token.start, decimal_marker=".")
                        end_time = SubtitleFormatter.format_timestamp(
                            token.end
                            if token == sentence.tokens[-1]
                            else sentence.tokens[i + 1].start,
                            decimal_marker=".",
                        )

                        text_line = ""
                        for j, inner_token in enumerate(sentence.tokens):
                            if i == j:
                                text_line += inner_token.text.replace(
                                    inner_token.text.strip(),
                                    f"<b>{inner_token.text.strip()}</b>",
                                )
                            else:
                                text_line += inner_token.text
                        text_line = text_line.strip()

                        vtt_content.append(f"{start_time} --> {end_time}")
                        vtt_content.append(text_line)
                        vtt_content.append("")
                else:
                    # å¦‚æœæ²¡æœ‰tokensï¼Œç›´æ¥ä½¿ç”¨å¥å­çº§åˆ«çš„æ—¶é—´æˆ³
                    start_time = SubtitleFormatter.format_timestamp(sentence.start, decimal_marker=".")
                    end_time = SubtitleFormatter.format_timestamp(sentence.end, decimal_marker=".")
                    text_line = sentence.text.strip()

                    vtt_content.append(f"{start_time} --> {end_time}")
                    vtt_content.append(text_line)
                    vtt_content.append("")
        else:
            for sentence in result.sentences:
                start_time = SubtitleFormatter.format_timestamp(sentence.start, decimal_marker=".")
                end_time = SubtitleFormatter.format_timestamp(sentence.end, decimal_marker=".")
                text_line = sentence.text.strip()

                vtt_content.append(f"{start_time} --> {end_time}")
                vtt_content.append(text_line)
                vtt_content.append("")

        return "\n".join(vtt_content)

    @staticmethod
    def _aligned_token_to_dict(token: AlignedToken) -> Dict[str, Any]:
        """å°†å¯¹é½çš„tokenè½¬æ¢ä¸ºå­—å…¸"""
        return {
            "text": token.text,
            "start": round(token.start, 3),
            "end": round(token.end, 3),
            "duration": round(getattr(token, 'duration', token.end - token.start), 3),
        }

    @staticmethod
    def _aligned_sentence_to_dict(sentence: AlignedSentence) -> Dict[str, Any]:
        """å°†å¯¹é½çš„å¥å­è½¬æ¢ä¸ºå­—å…¸"""
        tokens_list = []
        if hasattr(sentence, 'tokens') and sentence.tokens:
            tokens_list = [SubtitleFormatter._aligned_token_to_dict(token) for token in sentence.tokens]
        
        return {
            "text": sentence.text,
            "start": round(sentence.start, 3),
            "end": round(sentence.end, 3),
            "duration": round(getattr(sentence, 'duration', sentence.end - sentence.start), 3),
            "tokens": tokens_list,
        }

    @staticmethod
    def to_json(result: AlignedResult) -> str:
        """
        æ ¼å¼åŒ–ä¸ºJSON
        
        Args:
            result: è½¬å½•ç»“æœ
            
        Returns:
            str: JSONæ ¼å¼å†…å®¹
        """
        # å¤„ç†ç©ºç»“æœ
        if not result:
            return json.dumps({"sentences": [], "words": []}, ensure_ascii=False, indent=2)
            
        output_dict = {
            "text": result.text if hasattr(result, 'text') else "",
            "sentences": [
                SubtitleFormatter._aligned_sentence_to_dict(sentence) 
                for sentence in (result.sentences if result.sentences else [])
            ],
        }
        return json.dumps(output_dict, indent=2, ensure_ascii=False)
